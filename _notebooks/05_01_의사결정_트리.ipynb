{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. 의사결정 트리 알고리즘\n",
    "> 트리기반 모델인 의사결정 트리 알고리즘을 배워보고 실습을 진행해봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 5]\n",
    "- permalink: /decision_tree\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1. 트리란?\n",
    "\n",
    "의사결정 트리는 트리기반의 머신러닝 모델입니다. 그러나 컴퓨터 사이언스를 배우지 않은 여러분은 '트리'라는 자료구조를 잘 모르실테니 우선 '트리'에 대해 먼저 설명드리겠습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://s3.ap-northeast-2.amazonaws.com/learn.codestate.com/sos/Data+Structure/Advanced%20Data%20Structures/Untitled%204.png)\n",
    "\n",
    "트리는 '노드'로 구성된 계층적 자료구조입니다. '노드'는 위 그림에 있는 동그라미에 해당하는데, 트리의 기본 요소를 의미합니다. 트리에는 루트(최상위 노드)가 존재하고, 루트에서부터 시작해서 자식노드들이 아래로 뻗어나가게 됩니다. 각 노드는 여러개의 자식노드를 가질 수 있는데, 최대 N개까지만 가질 수 있는 트리를 N진 트리라고 합니다. 예를 들어 위 그림처럼 각 노드가 최대 2개의 자식노드를 가질 수 있으면 그런 트리를 이진트리라고 합니다. 모양이 꼭 뒤집어 놓은 나무같다고 해서 '트리'라고 부른다고 합니다.\n",
    "<br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 의사결정 트리 알고리즘이란?\n",
    "\n",
    "의사결정 트리 알고리즘은 트리 구조를 이용한 매우 직관적인  머신러닝 모델로, 분류와 회귀가 모두 가능한 지도학습 모델입니다. 아래의 예시를 봅시다. <br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/01.jpg?raw=true)\n",
    "\n",
    "만약 여러분에게 겨울에 찍은 가족 사진을 분류해볼래? 라고 말한다면 여러분은 어떤 기준으로 이미지를 분류해내실 건가요? <br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/02.jpg?raw=true)\n",
    "\n",
    "가장 먼저 '사진'을 찾아달라고 했기 때문에, '사진'이 아닌 '그림(만화)'를 걸러낼 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/03.jpg?raw=true)\n",
    "\n",
    "그리고 나서 위 처럼 '겨울'사진이 아닌 사진을 걸러낼 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/04.jpg?raw=true)\n",
    "\n",
    "마지막으로 사진에 여러명의 사람들이 있는 저 한 장의 사진을 겨울 가족 사진일 것이라고 분류해낼 수 있습니다. 의사결정 트리는 이렇게 여러개의 질문으로 데이터를 분리해내는 방법이고, 각 질문마다 데이터가 나뉘게 됩니다. 매우 직관적이죠? 학습시에는 이런 트리구조를 생성해서 파일로 저장하고, 테스트시에는 저장된 파일을 불러와서 사용하게 됩니다.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 의사결정 트리의 학습 : ID3 알고리즘\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/05.jpg?raw=true)\n",
    "\n",
    "그렇다면 이러한 의사결정 트리는 어떻게 학습될까요? 우선 위의 예제를 그대로 사용해봅시다. 아래와 같은 학습데이터가 있습니다. 우리는 3차원 데이터를 사용하였습니다. (이미지 데이터가 아닙니다) 우선 (1. 사진인지 만화인지), (2. 겨울사진인지 아닌지), (3. 사람이 여러명인지 한명인지)의 속성을 가지고 있고, 정답열(라벨)로 우리가 찾던 겨울 가족사진인지 아닌지에 대한 여부가 기록되어있습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/06.jpg?raw=true)\n",
    "\n",
    "컴퓨터는 각 속성(열)을 질문처럼 만들어서 맞는 경우 오른쪽으로, 틀리는 경우 왼쪽으로 보내는 트리를 만들어냅니다. 매우 간단하죠? 그런데 속성(열)이 총 3개 있으니 질문의 순서에 따라 위 처럼 다양한 종류의 트리가 만들어질 수 있습니다. 때문에 이 질문의 순서를 정하는 일이 중요해보입니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/07.jpg?raw=true)\n",
    "\n",
    "질문이 효율적이려면, 하나의 질문에서 많은 오답데이터를 걸러낼 수 있어야합니다. 위를 보면 (1. 사진인지 만화인지)는 총 4장의 오답을 걸러내서, 다음번부터는 4장만 확인하면 됩니다. 그에 비해 나머지 두개의 질문은 3장의 오답을 걸러내서, 다음번에 5장의 사진을 분류해야합니다. 따라서 (1. 사진인지 만화인지)가 가장 좋은 질문이라고 할 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/08.jpg?raw=true)\n",
    "\n",
    "그 다음에 2개의 질문 중 어떤 질문이 먼저일지 골라야합니다. (2. 겨울사진인지 아닌지)는 1장의 사진을 걸러내서 다음번에 4장의 이미지를 분류해야합니다. 그에 비해 (3. 사람이 여러명인지 한명인지)는 2장의 사진을 걸러내서 다음 번에 3장의 사진을 분류해야합니다. 따라서 (3. 사람이 여러명인지 한명인지)가 더 좋은 질문이라고 할 수 있습니다.<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/09.jpg?raw=true)\n",
    "\n",
    "마지막으로 (2. 겨울사진인지 아닌지)를 이용해 최종적인 분류를 마치게 됩니다. 이렇게 의사결정 트리를 구현할 수 있습니다. 그렇다면 이러한 순서는 어떻게 기계적으로 구현할 수 있을까요? 우리는 여기서 정보이론 시간에 배운 엔트로피(Entropy)를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. ID3 알고리즘의 수학적 이해\n",
    "\n",
    "ID3 알고리즘은 실제로 구현할 때 정보이론의 엔트로피를 계산하여 구현합니다. 엔트로피를 다시 리마인드 해봅시다. \n",
    "\n",
    "<br>\n",
    "$$\n",
    "H(x) =  \\sum_{i} -P_i \\cdot \\log P_i\n",
    "$$\n",
    "<br>\n",
    "\n",
    "엔트로피는 위의 공식으로 구할 수 있습니다. 이전에 설명했다시피, $-\\log P_i$들의 기댓값을 구한 것이 엔트로피라고 설명했습니다. 그러면 예시 상황의 엔트로피를 구해봅시다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/10.jpg?raw=true)\n",
    "\n",
    "총 8장의 사진 중 겨울 가족사진(Yes)가 나올 확률은 $\\frac{1}{8}$로 엔트로피는 $H(Yes) = -\\frac{1}{8} \\cdot \\log \\frac{1}{8}$입니다. 그리고 겨울 가족사진이 아닌 사진(No)가 나올 확률은 $\\frac{7}{8}$로 엔트로피는 $H(Yes) = -\\frac{7}{8} \\cdot \\log \\frac{7}{8}$입니다. 따라서 $\\sum Entropy = -\\frac{1}{8} \\cdot \\log \\frac{1}{8} -\\frac{7}{8} \\cdot \\log \\frac{7}{8}$로 0.543이 됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
