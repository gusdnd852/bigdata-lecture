{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 알고리즘\n",
    "> 확률기반 모델인 나이브베이즈 알고리즘을 배워보고 실습을 진행해봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 4]\n",
    "- permalink: /naive_bayes\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 1. 나이브 베이즈 알고리즘이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day2/92.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이번에 알려드릴 나이브 베이즈(Naive Bayes) 알고리즘은 분류 기법에서 사용되는 알고리즘 중 하나입니다. '나이브 베이즈'는 '순진하다'의 의미를 갖는 'naive'와 앞에서 학습한 '베이즈 정리'의 '베이즈'가 합쳐진 단어입니다. 그렇다면 왜 순진하다고 불릴까요? 나이브 베이즈 알고리즘은 데이터들이 서로 영향을 미치지 않는 동등하고 **독립적인 데이터라고 가정**하기 때문입니다. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.reviewjournal.com/wp-content/uploads/2019/04/12067517_web1_web_megabucks_sunsetstation.jpg)\n",
    "\n",
    "예시를 하나 들어보겠습니다. 만약 여러분이 **녹색 티셔츠를 입고 갔을 때, 라스베가스에서 잭팟이 터질 확률**이 얼마나 될까요? 사실 일반적인 경우, 두 사건은 관련이 거의 없다고 말 할 수 있습니다. 따라서 녹색티셔츠를 입고 갔을 때, **라스베가스에서 잭팟이 터질 확률과 그냥 아무 옷이나 입고 갔을 때 잭팟이 터질 확률이나 거의 비슷**하다고 할 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "이런 것을 사건의 독립이라고 합니다. 두 사건이 연관이 없는 것이죠. 그러나 실세계에서는 많은 요소들이 독립적이지 않습니다. 오히려 많은 사건들이 종속적이죠. 모든 사건들이 종속적이라면 모든 곱확률(교집합)을 구해줘야 하기 때문에 계산하기 너무 힘들어집니다. 따라서 어느정도 **정확한 확률을 포기하더라도 계산의 편리함을 위해 모든 사건을 그냥 독립적이라고 가정하고 문제를 푸는 것입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "간단한 수식을 통해 확인해보겠습니다. 만약 두 사건 A와 B가 독립일 경우, 다음과 같이 작성할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X \\cap Y) = P(X)P(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 베이즈 정리는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X|A) = \\frac{P(A|X)P(X)}{P(A)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때, 위 식에 있는 사건 $A$를 $A \\cap B$로 놓고 생각하면 아래의 식처럼 생각 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X|A \\cap B) = \\frac{P(A \\cap B|X)P(X)}{P(A \\cap B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 독립으로 바라보는 나이브 베이즈 알고리즘에서는 **$P(A \\cap B|X)$** 와 **$P(A \\cap B)$**가 같기 때문에,  변경해줄 수 있습니다. 각 식을 변경해주면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A \\cap B|X) = P(A|X)P(B|X)$$\n",
    " \n",
    "$$P(A \\cap B) = P(A)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경된 식을 원래의 베이즈 정리에 대입하면 다음과 같은 결과가 도출되는 것을 확인 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X|A \\cap B) = \\frac{P(A|X)P(B|X)P(X)}{P(A)P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "교집합으로 구해야하는 부분이 모두 사라지기 때문에 매우 편리하게 계산할 수 있습니다. 지금은 사건이 $A$와 $B$ 두개 뿐이지만, 만약 사건이 $A$, $B$, $C$ ... 와 같이 많아진다면 $A \\cap B$, $A \\cap C$, $B \\cap C$ 등을 다 구해야합니다.\n",
    "\n",
    "\n",
    "<br>\n",
    "나이브 베이즈 알고리즘은 이와 같은 식을 바탕으로 스팸 메일 분류, 텍스트 분류, 감정 분석, 추천 시스템 등 다양하게 활용되고 있습니다. 위의 야외 행사에 대한 예시를 적용해보면 날씨에 대한 확률, 기온에 대한 확률, 습도에 대한 확률, 바람에 대한 확률이 각각 따로 곱해지는 것이 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. 나이브 베이즈 알고리즘 예제\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day4/spam.jpg?raw=true)\n",
    "\n",
    "나이브 베이즈를 이용해 스펨메일을 필터링 해봅시다. 나이브 베이즈 알고리즘과 함께 여러가지 자연어 처리 기법들을 배워봅시다.\n",
    "<br><br>\n",
    "\n",
    "#### 2.1. 데이터에 대한 설명\n",
    "\n",
    "이메일의 내용을 갖고서 스팸인지 또는 햄(스팸이 아닌 이메일)인지 분류하는 데이터는 다음과 같은 예제를 갖고 있습니다.\n",
    "\n",
    "\n",
    "| Text | Tag | \n",
    "|:-----|:----|\n",
    "| free message | Spam |\n",
    "| send me a messsage | Ham |\n",
    "| are you free tomorrow? | Ham |\n",
    "| where is tesseract? | Spam |\n",
    "| where are you now? | Ham |\n",
    "| buy awesome tv | Spam |\n",
    "\n",
    "<br>\n",
    "예를 들어, `I cooked a salmon` 이런 문장인 경우 나이브 베이즈 알고리즘을 사용해서 Spam인지 또는 Ham인지 확률을 알아내는 것이 목표입니다. 베이즈 정리의 문제는 주어지는 데이터의 종속적 관계 때문에 연상량이 급격하게 늘어나게 됩니다. 예를 들어 이메일속의 단어들의 순서는 다른 단어가 나타날 확률을 의미할 수 있으며, 이는 각각의 단어가 다른 단어에 종속적임을 의미하게 됩니다. 예를 들어서 \"카지노\" 라는 단어가 나오면 그에 따라서 도박과 관련된 단어가 나올 확률이 높을 것 입니다. <br><br>\n",
    "\n",
    "나이브 베이즈는 이러한 현실적인 가정을 무시하고 모든 단어(또는 features)가 모두 **독립적(Independent)이라고 가정**을 합니다.물론 현실적으로 맞지는 않지만, 그럼에도 불구하고 이러한 가정은 계산량은 줄여주면서 잘 작동합니다. <br><br>\n",
    "\n",
    "많은 통계학자들이 가정 자체가 틀렸는데 왜 이렇게 잘 작동하는지 많은 연구를 하였는데.. 그중 하나의 설명이 좀 개인적으로 와닿았습니다. 만약 스팸을 정확하게 모두 걸러낸다면 신뢰구간 51% ~ 99%가 의미가 있는 것인가 입니다. 즉 test결과 자체가 정확하다면, 매우 정확한 확률론적 계산을 하는 것 자체가 크게 중요하지 않다는 의미입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample_data/spam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. 나이브 베이즈 알고리즘 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이브 베이즈 알고리즘은 단순하고 빠릅니다.** 나이브 베이즈 알고리즘은 각 데이터들의 연관 관계를 고려하지 않습니다. 독립된 상황에서만 생각하기 때문에 사전 조건이 간단해지므로 결과를 도출하기까지 단순해지고 빠릅니다. 그래서 많은 데이터를 사용할 때 효과적으로 결과를 도출할 수 있습니다. 그렇다면 어떤 데이터들에게 적용시키는 것이 유리할까요? 서로 독립이라고 가정을 하기 때문에 기존 데이터들이 연속적이기보다는 이산적일 때 성능이 좋습니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. 나이브 베이즈 알고리즘 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터간의 독립성이 없다면 부정확한 결과가 도출될 수 있습니다. 하나의 데이터가 다른 데이터에 영향이 없는 독립된 상황에서의 사용이 바람직합니다. 한정된 상황에서의 사용과 그로 인한 정확성의 불안정성이 나이브 베이즈 알고리즘의 대표적인 단점으로 볼 수 있습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
