{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 나이브 베이즈 알고리즘\n",
    "> 확률기반 모델인 나이브베이즈 알고리즘을 배워보고 실습을 진행해봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 4]\n",
    "- permalink: /naive_bayes\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 1. 나이브 베이즈 알고리즘이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day2/92.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이번에 알려드릴 나이브 베이즈(Naive Bayes) 알고리즘은 분류 기법에서 사용되는 알고리즘 중 하나입니다. '나이브 베이즈'는 '순진하다'의 의미를 갖는 'naive'와 앞에서 학습한 '베이즈 정리'의 '베이즈'가 합쳐진 단어입니다. 그렇다면 왜 순진하다고 불릴까요? 나이브 베이즈 알고리즘은 데이터들이 서로 영향을 미치지 않는 동등하고 **독립적인 데이터라고 가정**하기 때문입니다. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.reviewjournal.com/wp-content/uploads/2019/04/12067517_web1_web_megabucks_sunsetstation.jpg)\n",
    "\n",
    "예시를 하나 들어보겠습니다. 만약 여러분이 라스베가스에 갔다고 해봅시다. 이 때, 라스베가스에서 **녹색 옷을 입고 잭팟이 터질 확률**이 얼마나 될까요? 사실 일반적인 경우, 두 사건은 관련이 거의 없다고 말 할 수 있습니다. 따라서 **녹색티셔츠를 입고 잭팟이 터질 확률과 그냥 아무 옷이나 입고 갔을 때 잭팟이 터질 확률이나 거의 비슷**하다고 할 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "이런 것을 사건의 독립이라고 합니다. 두 사건이 연관이 없는 것이죠. 그러나 실세계에서는 많은 요소들이 독립적이지 않습니다. 오히려 실세계에서는 대부분의 사건들이 종속적이죠. 모든 사건들이 종속적이라면 모든 곱확률(교집합)을 구해줘야 하기 때문에 계산하기 너무 힘들어집니다. 따라서 어느정도 **정확한 확률을 포기하더라도 계산의 편리함을 위해 모든 사건을 그냥 독립적이라고 가정하고 문제를 푸는 것입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. 수식 풀이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 수식을 통해 확인해보겠습니다. 만약 두 사건 A와 B가 독립일 경우, 다음과 같이 작성할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "$$P(X \\cap Y) = P(X)P(Y)$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 베이즈 정리는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "$$P(X|Z) = \\frac{P(Z|X)P(X)}{P(Z)} $$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때, 위 식에 있는 사건 $Z$를 임의의 $A \\cap B$라고 놓고 생각하면 아래의 식처럼 생각 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "$$P(X|A \\cap B) = \\frac{P(A \\cap B|X)P(X)}{P(A \\cap B)} $$\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 독립으로 바라보는 나이브 베이즈 알고리즘에서는 **$P(A \\cap B|X)$** 와 **$P(A \\cap B)$**가 같기 때문에,  변경해줄 수 있습니다. 각 식을 변경해주면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "$$P(A \\cap B|X) = P(A|X)P(B|X)$$\n",
    "<br>\n",
    "$$P(A \\cap B) = P(A)P(B)$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경된 식을 원래의 베이즈 정리에 대입하면 다음과 같은 결과가 도출되는 것을 확인 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "$$P(X|A \\cap B) = \\frac{P(A|X)P(B|X)P(X)}{P(A)P(B)} $$\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "교집합으로 구해야하는 부분이 모두 사라지기 때문에 매우 편리하게 계산할 수 있습니다. 지금은 사건이 $A$와 $B$ 두개 뿐이지만, 만약 사건이 $A$, $B$, $C$ ... 와 같이 많아진다면 $A \\cap B$, $A \\cap C$, $B \\cap C$ 등을 다 구해야합니다. 나이브 베이즈 알고리즘은 이와 같은 식을 바탕으로 스팸 메일 분류, 텍스트 분류, 감정 분석, 추천 시스템 등 다양하게 활용되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. 나이브 베이즈 알고리즘 예제\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day4/spam.jpg?raw=true)\n",
    "\n",
    "나이브 베이즈를 이용해 스펨메일을 필터링 해봅시다. 나이브 베이즈 알고리즘과 함께 여러가지 자연어 처리 기법들을 배워봅시다. 아래 링크에서 데이터를 다운로드 받아서 sample_data 폴더에 넣어주세요.\n",
    "<br><br>\n",
    "\n",
    "https://github.com/gusdnd852/bigdata-lecture/files/4970108/spam.zip\n",
    "\n",
    "```\n",
    "root경로\n",
    "    |_...\n",
    "    |_sample_data\n",
    "        |_spam.csv\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.1. 데이터에 대한 설명\n",
    "\n",
    "이메일의 내용을 갖고서 스팸인지 또는 햄(스팸이 아닌 이메일)인지 분류하는 데이터는 다음과 같은 예제를 갖고 있습니다.\n",
    "\n",
    "\n",
    "|Class| Text | \n",
    "|:----|:-----|\n",
    "|Spam| free message |\n",
    "|Ham| send me a messsage |\n",
    "|Ham| are you free tomorrow? |\n",
    "|Spam| where is tesseract? |\n",
    "|Ham| where are you now? |\n",
    "|Spam| buy awesome tv |\n",
    "\n",
    "<br>\n",
    "예를 들어, `I cooked a salmon` 이런 문장인 경우 나이브 베이즈 알고리즘을 사용해서 Spam인지 또는 Ham인지 확률을 알아내는 것이 목표입니다. 베이즈 정리의 문제는 주어지는 데이터의 종속적 관계 때문에 연상량이 급격하게 늘어나게 됩니다. 예를 들어 이메일속의 단어들의 순서는 다른 단어가 나타날 확률을 의미할 수 있으며, 이는 각각의 단어가 다른 단어에 종속적임을 의미하게 됩니다. 예를 들어서 \"카지노\" 라는 단어가 나오면 그에 따라서 도박과 관련된 단어가 나올 확률이 높을 것 입니다. <br><br>\n",
    "\n",
    "나이브 베이즈는 이러한 현실적인 가정을 무시하고 모든 단어(또는 features)가 모두 **독립적(Independent)이라고 가정**을 합니다.물론 현실적으로 맞지는 않지만, 그럼에도 불구하고 이러한 가정은 계산량은 줄여주면서 잘 작동합니다. <br><br>\n",
    "\n",
    "많은 통계학자들이 가정 자체가 틀렸는데 왜 이렇게 잘 작동하는지 많은 연구를 하였는데.. 그중 하나의 설명이 좀 개인적으로 와닿았습니다. 만약 스팸을 정확하게 모두 걸러낸다면 신뢰구간 51% ~ 99%가 의미가 있는 것인가 입니다. 즉 test하면 대부분의 spam을 잘 맞추는데, 확률론적으로 매우 정확한 계산을 해내는 것 자체가 크게 중요하지 않다는 의미입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.2. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 필요한 라이브러리 모두 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ? b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ? b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('sample_data/spam.csv')\n",
    "dataset = dataset.iloc[:, 0:2]\n",
    "dataset.columns = ['class', 'text']\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                                               \n",
       "      count unique                                                top freq\n",
       "class                                                                     \n",
       "ham    4825   4516                             Sorry, I'll call later   30\n",
       "spam    747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 13.5% 만이 spam으로 분류되어 있습니다. 즉 class imbalance(불균형) 문제가 있는 데이터 셋입니다. unique 메세지를 보면 duplicate text가 존재함을 알 수 있습니다. (총 4825개인데 4516개의 unique값이 존재함)\n",
    "<br><br>\n",
    "\n",
    "또한 아래의 histogram에서 알 수 있듯이, 대부분의 Ham의 글자길이는 대부분 100이하에 있고, Spam의 경우는 150쯤에 있습니다. 즉 길이의 차이가 있으며, Spam이 문장의 길이가 더 깁니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['length'] = dataset['text'].apply(len)\n",
    "ax = dataset.hist('length', by='class', bins=50, figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 전처리합니다. 아래와 같은 과정을 거쳐서 데이터를 전처리할 계획입니다.\n",
    "<br><br>\n",
    "\n",
    "1. 구두점, Stop Word 제거 : 구두점과 너무 자주 쓰이는 단어들(a, the, of, at 등)을 제거합니다. 이런 단어들(Stop Word)과 구두점들은 스팸이던 햄이던 상관없이 너무 자주 등장하기 때문에 오히려 분류에 방해가 됩니다.\n",
    "\n",
    "2. Tokenizing : 단어를 띄어쓰기 기준으로 잘라서 리스트로 자릅니다. 단어들은 string이 아니라 list의 타입이 되고, 그 리스트에 단어들이 각각 들어가게 됩니다.\n",
    "\n",
    "3. Word Encoding : 모든 단어를 숫자로 바꿔줍니다. 하나의 단어는 하나의 고유한 숫자가 됩니다. 컴퓨터는 자연어를 처리할 수 없기 때문에 숫자로 바꿔줘야합니다. (2주차 딥러닝 수업때는 더욱 진보된 워드 임베딩에 대해 배웁니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords') \n",
    "# Stop Word 목록을 다운로드 받습니다.\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    # Remove Punctuations\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    cleaned_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                          [Ok, lar, Joking, wif, u, oni]\n",
       "2       [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3           [U, dun, say, early, hor, U, c, already, say]\n",
       "4       [Nah, dont, think, goes, usf, lives, around, t...\n",
       "                              ...                        \n",
       "5567    [2nd, time, tried, 2, contact, u, U, 傭50, Poun...\n",
       "5568                      [b, going, esplanade, fr, home]\n",
       "5569                     [Pity, mood, Soany, suggestions]\n",
       "5570    [guy, bitching, acted, like, id, interested, b...\n",
       "5571                                   [Rofl, true, name]\n",
       "Name: text, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터가 많아서 시간이 조금 걸립니다.\n",
    "\n",
    "dataset['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.4 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 학습/테스트 세트로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset['class']\n",
    "features = dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,) (4457,)\n",
      "(1115,) (1115,)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8 * len(dataset)) \n",
    "\n",
    "train_feature = features[:split]\n",
    "train_label = label[:split]\n",
    "\n",
    "test_feature = features[split:]\n",
    "test_label = label[split:]\n",
    "\n",
    "print(train_feature.shape, train_label.shape)\n",
    "print(test_feature.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습 파이프라인을 만듭니다. sklearn에서는 Pipeline이라는 클래스로 두 모델을 연결할 수 있습니다. 가장 먼저 `CounterVectorizer`를 이용해 단어를 숫자로 인코딩 한뒤, 인코딩된 숫자를 곧 바로 `NaiveBayes` 모델의 입력으로 넣어서 학습하는 파이프라인을 고안해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('word_encoder',\n",
       "                 CountVectorizer(analyzer=<function preprocess at 0x000001DB642E3598>)),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('word_encoder', CountVectorizer(analyzer=preprocess)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97847533632287"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pipeline.predict(test_feature)\n",
    "accuracy_score(test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       970\n",
      "        spam       0.92      0.92      0.92       145\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.95      0.95      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성공적으로 스팸메일을 분류하는데 성공했습니다. 모델을 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/naive_bayes.pkl']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn 모델 저장\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./models/'):\n",
    "    os.makedirs('./models/')\n",
    "\n",
    "joblib.dump(pipeline, './models/naive_bayes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 모델 불러오기\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./models/'):\n",
    "    os.makedirs('./models/')\n",
    "\n",
    "pipeline = joblib.load('./models/naive_bayes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Ham 데이터 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  Die... I accidentally deleted e msg i suppose 2 put in e sim archive. Haiz... I so sad...\n",
      "label :  ham\n"
     ]
    }
   ],
   "source": [
    "text_0 = test_feature.iloc[0]\n",
    "label_0 = test_label.iloc[0]\n",
    "print('text : ', text_0)\n",
    "print('label : ', label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([text_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Spam 데이터 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  Welcome to UK-mobile-date this msg is FREE giving you free calling to 08719839835. Future mgs billed at 150p daily. To cancel send \\go stop\\\" to 89123\"\n",
      "label :  spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = test_feature.iloc[1]\n",
    "label_1 = test_label.iloc[1]\n",
    "print('text : ', text_1)\n",
    "print('label : ', label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([text_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. 나이브 베이즈 알고리즘 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이브 베이즈 알고리즘은 단순하고 빠릅니다.** 나이브 베이즈 알고리즘은 각 데이터들의 연관 관계를 고려하지 않습니다. 독립된 상황에서만 생각하기 때문에 사전 조건이 간단해지므로 결과를 도출하기까지 단순해지고 빠릅니다. 그래서 많은 데이터를 사용할 때 효과적으로 결과를 도출할 수 있습니다. 그렇다면 어떤 데이터들에게 적용시키는 것이 유리할까요? 서로 독립이라고 가정을 하기 때문에 기존 데이터들이 연속적이기보다는 이산적일 때 성능이 좋습니다. (실습때 속도가 느린건 다른 예제에 비해 처리할 데이터가 많아서입니다.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 5. 나이브 베이즈 알고리즘 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터간의 독립성이 없다면 부정확한 결과가 도출될 수 있습니다. 하나의 데이터가 다른 데이터에 영향이 없는 독립된 상황에서의 사용이 바람직합니다. 한정된 상황에서의 사용과 그로 인한 정확성의 불안정성이 나이브 베이즈 알고리즘의 대표적인 단점으로 볼 수 있습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
