{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 다양한 회귀모델\n",
    "> 이번 시간에는 다양한 회귀모델에 대해 공부해봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 5]\n",
    "- permalink: /regressions\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 회귀 모델이란?\n",
    "\n",
    "회귀 모델을 한 마디로 정의하면 **'어떤 자료에 대해서 그 값에 영향을 주는 조건을 고려하여 구한 평균'** 입니다. 즉, 데이터를 가장 잘 설명하여 데이터의 평균과 같은 함수를 찾는 것이 회귀번숙이며, 통계학적인 관점에서 보면 모든 데이터는 아래와 같은 수식으로 표현할 수 있다고 가정합니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/reg00.png?raw=true)\n",
    "\n",
    "위 수식에서 h() 가 위에서 말한 조건에 따른 평균을 구하는 함수이며 우리는 이것을 보통 '회귀 모델'이라고 부릅니다. 이 함수는 어떤 조건(x1, x2, x3, ...)이 주어지면 각 조건의 영향력(beta1, beta2, beta3, ...)을 고려하여 해당 조건에서의 평균값을 계산해 주는 것이죠. 뒤에 붙는 e 는 '오차항'을 의미합니다. 측정상의 오차나 모든 정보를 파악할 수 없는 점 등 다양한 현실적인 한계로 인해 발생하는 불확실성이 여기에 포함됩니다. 이것은 일종의 '잡음(noise)'인데, 이런 잡음은 이론적으로 보면 평균이 0이고 분산이 일정한 정규 분포를 띄는 성질이 있습니다.\n",
    "<br><br>\n",
    "\n",
    "우리가 회귀 분석을 한다는 것은 이 h() 함수가 무엇인지를 찾는 과정을 의미합니다. 그럼 우리가 추정한 회귀 모델이 정말 h() 라는 걸 어떻게 확신할 수 있을까요? 엄밀히 말하면 정확히 맞다는 것을 알 방법은 없습니다. 다만 그럴 것이라고 어느 정도는 확신할 수 있는 방법이 있는데, 바로 우리가 만든 회귀 모델의 예측치와 실측치 사이의 차이인 **'잔차(residual)'가 정말 우리가 가정한 오차항(e)과 비슷한지 확인하는 것**입니다. <br><br>\n",
    "\n",
    "![](https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/Jr9/image/SbI5NgVY5ZLzvG6QCT8hUcC00lA.jpg)\n",
    "\n",
    "\n",
    "어쨌든 우리는 최대한 실제 h() 에 가깝게 회귀 모델을 만드는 것이 목표입니다. 이전시간에 이미 언급했지만, 만약 **추정을 잘못하면 몇몇 중요한 조건들을 반영하지 못해 h()의 일부분만 회귀 모델로 만들 수 있는데 이것을 'underfitting' 이라고 부릅니다.** 반대로 실제 종속변수에 영향을 주는 조건이 아닌 단순한 **'잡음'을 평균에 영향을 주는 조건으로 착각하고 모델에 반영할 수도 있는데 이런 것을 'overfitting' 이라고 부릅니다.** 보통 overfitting 문제를 많이 다루고 있지만 사실 현실 세계에서 우리가 만드는 대부분의 회귀 모델은 underfitting 문제도 같이 갖고 있습니다. 다시 말해, 우리가 만드는 대부분의 회귀 모델들은 h()의 일부분과 e의 일부분을 같이 반영하고 있는 상태입니다. 단지 둘 중 어느 쪽이 더 많은 비중을 차지하고 있느냐의 문제일 뿐이지요.<br><br>\n",
    "\n",
    "한편 우리가 모델을 만드는 이유는 **현실을 좀 더 단순한 형태로 표현하기 위해서**입니다. 그리고 이렇게 단순화하려면 불필요하다고 생각하는 정보들을 버려야 합니다. 이때, 우리가 회귀 모델을 만들기 위해 버린 정보들이 무엇인지를 설명하는 것이 회귀 모델의 가정(assumption)입니다. 즉, 회귀 모델을 만들 때 '실제 데이터는 이러 이러한 특성을 갖고 있다고 가정'하는 것입니다. 따라서 이런 가정이 많아질수록 모델은 좀 더 단순해집니다. 반대로 가정을 최소화할수록 모델은 복잡해지겠죠. 여기서 설명할 다양한 회귀 모델들은 이렇게 데이터가 어떤 특성을 갖고 있다고 가정했느냐에 따라 나뉘어 집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. 선형성 vs. 비선형성\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/9987BB345B88C60B33)\n",
    "\n",
    "가장 먼저 고려해야 할 가정은 **선형성**과 **비선형성**입니다. '선형성(linearity)'이란 것은 이전 강의에서도 말한 것 처럼 우리가 어떤것을 변화시키면 딱 그 만큼만 변화되는 것을 의미하며, 선형대수에서는 벡터의 두가지 연산(벡터합, 스칼라곱)을 만족해야 선형적이라고 할 수 있습니다. 즉, 어떤 집합의 원소쌍(아래 수식의 u와 v)에 대해서 함수 f()가 아래 두 가지 성질을 만족시키는 것을 말합니다 (직관적으로 잘 와닿지 않는 분들을 위해 쉽게 말하면, 일차 다항식을 선형 함수라고 생각하면 됩니다.\n",
    "\n",
    "- $f(c*u) = c*f(u)$  ---------- (스칼라곱)\n",
    "- $f(u+v) = f(u) + f(v)$  ---- (벡터 합)\n",
    "<br><br>\n",
    "\n",
    "그런데 이 부분에서 헷갈리는 점이 있는데, 회귀 모델에서 선형과 비선형을 구분할 때는 Y(독립변수)와 X(종속변수)의 관계를 기준으로 생각하면 안됩니다. **선형이냐 비선형이냐를 결정하는 대상은 '회귀 계수(W, 기울기 등)'입니다.** 다시 말해, 회귀식에서 x를 기준으로 선형 함수인지를 판단하는 것이 아닙니다. 왜냐하면 회귀 모델에서 우리가 추정해야 하는 미지수는 X(독립 변수)나 Y(종속 변수)가 아니라 W(회귀 계수, 기울기 등)이기 때문입니다.\n",
    "<br><br>\n",
    "\n",
    "어쨌든 우리가 배우는 대부분의 회귀 모델은 선형 회귀 모델입니다. 반면 최근에 크게 주목받고 있는 딥러닝은 대표적인 비선형 회귀 모델링 방법입니다. 선형 회귀 모델은 회귀 계수간의 관계가 비교적 직관적이기 때문에 각 조건의 영향력을 해석하기가 비선형 모델에 비해 쉽습니다. 대신 모든 조건들을 오직 선형 결합(쉽게 말해 더하기)으로만 표현해야 하기 때문에 표현력에 한계가 있습니다. **다시 말해 실제 모델링 대상이 되는 현실 데이터가 선형적이지 못한 데이터라면 정확한 회귀 모델을 만들 수 없습니다.** \n",
    "<br><br>\n",
    "\n",
    "선형 회귀 모델의 이런 한계점 때문에 모델의 **해석보다는 예측 자체가 중요한 복잡한 문제에 대해서는 딥러닝을 이용**합니다. 딥러닝은 비선형 회귀 모델이기 때문에 현실 세계의 복잡한 관계도 거의 대부분 표현이 가능합니다. 즉, underfitting 문제에서 상대적으로 자유롭습니다. 대신 불필요한 잡음을 모델에 반영하는 overfitting 문제가 발생할 가능성이 더 크기 때문에 이 문제를 피하기 위한 다양한 기법들이 연구되고 있죠. 정리하자면, 회귀 모델은 모델링 대상을 **회귀 계수의 선형 결합만으로 표현할 것인지 여부에 따라 '선형' 회귀 모델과 '비선형' 회귀 모델로 구분**됩니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 타겟 Y(종속변수)의 개수에 따른 구분 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
