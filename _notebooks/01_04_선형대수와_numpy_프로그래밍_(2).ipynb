{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 선형대수와 Numpy 프로그래밍 (2)\n",
    "> 머신러닝에 꼭 필요한 선형대수학 개념들을 배우고 이를 Numpy로 구현하는 방법을 배워봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 1]\n",
    "- permalink: /linear_algebra_with_numpy_2\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 시간에서 선형대수의 대략적인 개념과 numpy를 소개했습니다. 이번 챕터에서는 이제 본격적으로 행렬, 선형대수의 각종 연산들, 그리고 numpy의 고급 사용법에 대해 알아봅시다.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 1. 행렬\n",
    "\n",
    "행렬은 이미 많이 들어봐서 알고 있을 것입니다. 그러나 행렬이 진정으로 무엇을 의미하는지는 학교에서 잘 가르쳐주지 않습니다. 행렬을 알기 전에 \"변환\", 즉 \"Transformation\"이라는 단어에 대해 먼저 생각해봅시다. <br><br>\n",
    "\n",
    "#### 1.1. 변환 (Transformation)\n",
    "\n",
    "변환은 함수와 어느정도 일맥상통합니다. 함수는 어떤 수를 입력받아서 다른 수로 변환합니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/31.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "선형대수의 맥락에서 보자면, 특정 벡터를 다른 벡터로 변환하는 것이라고 볼 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/32.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "즉 아래와 같이 어떤 입력벡터를 움직여서 출력 벡터로 만드는 것을 생각해볼 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/33.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이러한 변환을 공간 전체에 있는 모든 벡터에 적용한다면, 아래처럼 진행이 될 수 있습니다. 공간에 있는 모든 벡터가 위와 같이 회전하거나 변환됩니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/41.gif?raw=true)\n",
    "<br><br><br>\n",
    "\n",
    "#### 1.2. 선형 변환 (Linear Transformation)\n",
    "그러나, 선형대수에서는 모든 종류의 변환을 다루지 않습니다. 선형대수에서는 모든 벡터가 선형성을 유지해야하기 때문에 \"선형 변환\"에 대하서만 다루고, \"비 선형 변환\"은 다루지 않습니다. 시각적으로 볼 때, 변환이 선형적(Linear)하다는 것은 두가지 속성을 의미합니다. \n",
    "<br><br>\n",
    "\n",
    "- 모든 벡터는 변환 이후에도 휘지 않고 직선이여야 한다. \n",
    "- 원점은 변환 이후에도 그대로 원점(0, 0)이여야 한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "두가지 조건을 만족하지 않는 경우 선형변환이라고 하지 않습니다. 아래처럼 변환 이후에 직선이 휘어서 곡선이 되어있거나, 원점이 다른 곳으로 이동하면 그러한 변환은 선형변환이 아닌, 비선형 변환입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/42.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "#### 1.3. 굳이 변환 이야기를 꺼내는 이유?\n",
    "선형 변환에 대해서 말씀 드린 이유는, 행렬이 바로 벡터를 선형 변환시키기 위한 도구이기 때문입니다. 선형대수의 장점은 하나의 연산이나 하나의 벡터에 대해 기하학적인 표현과 수치적인 표현이 모두 가능하다는 것에 있다고 이전에 말했습니다. 저는 지금까지 행렬에 대해서 기하학적으로 열심히 설명했던 것 입니다. 그러면 이러한 변환을 우리가 어떻게 수치적으로 계산할 수 있을까요?\n",
    "<br><br>\n",
    "\n",
    "예를 들어 $\\vec{v}$ = $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$라는 벡터가 변환 되었다고 합시다. 그러면 어떻게 이 변환 함수를 찾아낼 수 있을까요? 이 변환이 어떤 변환이였는지 계산하려면, 우리는 기저벡터가 어디에서 어디로 이동했는지만 알면 됩니다. 이 부분을 이해하기 위해서 앞 선 챕터에서 기저벡터에 대해 언급 했던 것 입니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "xy 평면공간의 정규직교 기저벡터는 $\\hat{i}$ = $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$과 $\\hat{j}$ = $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$입니다. 그리고 $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$는 -1$\\hat{i}$ + 2$\\hat{j}$가 됩니다. 여기까지는 이전 챕터에서 이야기 했던 내용입니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/43.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "변환을 적용하면, 벡터가 움직인다고 했고, 기저벡터 역시 벡터이기 때문에 움직입니다. 자 이제, 변환이 적용된 이후에 기저벡터를 transformed $\\hat{i}$과 transformed $\\hat{j}$이라고 해보겠습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/44.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "기존에 변환 전 $\\vec{v}$ = $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$ = -1 $\\hat{i}$ + 2 $\\hat{j}$ 였습니다. 마찬가지로 변환된 transformed $\\vec{v}$ = - 1 transformed $\\hat{i}$ + 2 transformed $\\hat{j}$로 이전의 비율(-1, 2)이 유지됩니다. <br><br>\n",
    "\n",
    "결론적으로 변환 전에 우리가 찾던 벡터 $\\vec{v}$(노란색)을 이루는 $\\hat{i}$와 $\\hat{j}$의 어떠한 선형결합이 변환 후에도 같은 결합으로 유지됩니다. 이 말은 즉, 단순히 $\\hat{i}$와 $\\hat{j}$가 변환 이후에 어디로 갔는지만 알면 벡터 $\\vec{v}$가 어디로 움직였는지도 알 수 있다는 말입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/45.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "변환 결과, 기저 $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$로 움직였고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$으로 움직였습니다. 따라서 변환된 벡터 $\\vec{v}$ = -1 * $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$ + 2 * $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$이 되고, 이 값은 $\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}$로 변환된 $\\vec{v}$의 위치와 동일합니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/46.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이렇게 기저벡터가 어디로 움직였는지만 알면, 해당 공간의 모든 벡터가 어디로 움직였는지 알 수 있게 됩니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/47.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "#### 1.4. 행렬의 본질\n",
    "\n",
    "위의 내용을 정리해서 써봅시다. $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$로 움직였고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$으로 움직였습니다. 따라서 임의의 벡터 $\\vec{v}$ = $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$는 변환 후에 x * $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$ + y * $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$이 됩니다. 이것을 조금 더 정리해서 쓰면 $\\begin{bmatrix} 1x + 3y \\\\ -2x + 0y \\end{bmatrix}$가 됩니다. 이제 슬슬 감이 오시나요?\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/48.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그래서 이 선형 변환 자체를 $\\begin{bmatrix} 1 & 3 \\\\ -2 & 0 \\end{bmatrix}$와 같은 하나의 행렬로서 정의할 수 있습니다.\n",
    "즉, 행렬은 벡터의 위치를 선형 변환 시키는 도구라고 할 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/49.gif?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shape\n",
    "\n",
    "행렬과 벡터의 Shape에 대해 알아봅시다. Shape이란 말 그대로, 행렬이나 벡터의 모양을 의미합니다.\n",
    "일반적으로 Shape은 (행의 수, 열의 수)로 표기합니다. 우리가 처음 봤던 가장 기본 형태인 2차원 벡터는 \n",
    "$\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$와 같이 표기합니다. 이와 같은 벡터는 (2, 1)의 Shape을 가진다고 할 수 있습니다. \n",
    "3차원 벡터인 $\\begin{bmatrix} 1 \\\\ -2 \\\\ 3 \\end{bmatrix}$는 행이 3개이므로 (3, 1)의 Shape를 갖고 \n",
    "$\\begin{bmatrix} 1 & 1 \\\\ -2 & 0 \\end{bmatrix}$과 같은 행렬은 (2, 2)의 Shape를 갖습니다.\n",
    "흔히, 이런 Shape을 2 x 2와 같이 표현하기도 합니다. numpy를 사용하면 행렬이나 벡터의 Shape을 매우 쉽게 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "# 행 2개, 열 1개\n",
    "vec_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 np.array 객체에 .shape를 붙이면 현재 객체의 shape를 알 수 있습니다.\n",
    "몇가지 예시를 더 보겠습니다.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_b = np.array([[1], \n",
    "                  [-2],\n",
    "                  [3]])\n",
    "\n",
    "# 행 3개, 열 1개\n",
    "vec_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "# 행 2개, 열 2개\n",
    "matrix_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 3. 행렬의 연산\n",
    "벡터 챕터에서는 가장 중요한 기본 연산인 벡터합과 스칼라 곱에 대해 배웠습니다. 행렬은 벡터보다 조금 더 다양한 연산을 가지고 있습니다. 아래에서 차례로 알아봅시다.\n",
    "<br><br>\n",
    "\n",
    "#### 3.1. 행렬 합 (= 벡터 합, Matrix Addition)\n",
    "행렬 합은 두 행렬을 더 합니다. 벡터 합과 동일한 방식으로 수행됩니다. 각 원소 자리에 있는 수를 더합니다.\n",
    "주의할 것은 벡터 합이나 행렬 합은 Shape가 동일할 때만 수행 가능합니다. Shape가 다른 경우 더할 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞는 경우 행렬 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [0, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape이 동일한 경우 (2, 2) & (2, 2)\n",
    "\n",
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[1, 1], \n",
    "                     [2, 3]])\n",
    "\n",
    "matrix_a + matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞지 않는 경우 행렬 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a6ec0b31b5ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                      [2, 3, 7]])\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmatrix_a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatrix_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# Shape 에러 발생!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "# Shape이 다른 경우 (2, 2) & (2, 3)\n",
    "\n",
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[1, 1, 0],\n",
    "                     [2, 3, 7]])\n",
    "\n",
    "matrix_a + matrix_b\n",
    "# Shape 에러 발생!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞는 경우 벡터 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape이 동일한 경우 (2, 1) & (2, 1)\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[1], \n",
    "                  [2]])\n",
    "\n",
    "vec_a + vec_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞지 않는 경우 벡터 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,1) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9842e485b732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 [2]])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mvec_a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvec_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# Shape 에러 발생!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (3,1) "
     ]
    }
   ],
   "source": [
    "# Shape이 다른 경우 (2, 1) & (3, 1)\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[1], \n",
    "                  [2],\n",
    "                  [2]])\n",
    "\n",
    "vec_a + vec_b\n",
    "# Shape 에러 발생!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 3.2. 스칼라 곱 (Scalar Multiplication)\n",
    "스칼라곱도 벡터에서 하던 방식과 동일하게 하면 됩니다. 모든 원소에 해당 스칼라를 곱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2],\n",
       "       [-4,  0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "scalar = 2\n",
    "\n",
    "matrix_a * scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 3.3. 원소곱 (Elementwise Multiplication)\n",
    "행렬의 각 자리 원소끼리 곱합니다. 행렬합과 마찬가지로 Shape이 동일해야합니다. * 연산자를 이용해 원소 곱 연산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2],\n",
       "       [-4,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[2, 2],\n",
    "                     [2, 2]])\n",
    "\n",
    "matrix_a * matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "벡터도 원소 곱이 가능합니다만, 벡터의 정의에 해당하는 2가지 연산(벡터합, 스칼라곱)에 해당되지 않기 때문에 여기에서 소개합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2],\n",
       "       [-4]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[2], \n",
    "                  [2]])\n",
    "\n",
    "vec_a * vec_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 3.4. 행렬 - 벡터 곱 (Matrix - Vector Multiplication)\n",
    "위에서 말한 케이스로, 행렬을 통해 벡터를 선형변환 시키는 연산입니다. 일반적으로 $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ @ $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$와 같은 연산이 있을 때, 대부분은 $\\begin{bmatrix} ax + by \\\\ cx + dy \\end{bmatrix}$와 같이 외우셨을 겁니다. (아래처럼)\n",
    "<br><br>\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/53.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그러나 본질은 여기에 있습니다. 왜 x에 a와 c가 곱해지는지, 왜 y왜 b와 d가 곱해지는지 알아야합니다. x에 a와 c가 곱해지는 이유는 x가 원래 x @ $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ = $\\begin{bmatrix} 1x \\\\ 0 \\end{bmatrix}$이였는데, $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$이 변환 이후에 $\\begin{bmatrix} a \\\\ b \\end{bmatrix}$로 변환되었기 때문에 그렇게 연산하는 것입니다. 그래서 x는 $\\begin{bmatrix} ax \\\\ cx \\end{bmatrix}$로 변환됩니다. y는 원래 y @ $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ = $\\begin{bmatrix} 0 \\\\ 1y \\end{bmatrix}$이였는데 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$이 변환 이후에 $\\begin{bmatrix} b \\\\ d \\end{bmatrix}$로 변환되었기 때문에 그렇게 연산하는 것입니다. 그래서 y는 $\\begin{bmatrix} by \\\\ dy \\end{bmatrix}$로 변환됩니다.\n",
    "<br><br>\n",
    "\n",
    "아래 수식을 보면 더 좋은 직관을 얻을 수 있을 것입니다.\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/50.gif?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Shape 규칙 (Rule of multiplication)\n",
    "\n",
    "벡터와 행렬 혹은 행렬과 행렬을 곱하려면 곱하는 두 벡터/행렬의 Shape이 맞아야합니다. 벡터 - 행렬곱과 행렬 - 행렬곱 (원소곱이 아닌 행렬 단위곱)에서는 아래와 같은 Shape에 대한 규칙이 있습니다. <br>\n",
    "\n",
    "- Rule of multiplication : (a, b) * (b, d) → (a, d)\n",
    "- 앞쪽 벡터/행렬의 b와 뒤쪽 벡터/행렬의 b는 동일해야한다.\n",
    "- 계산결과 나오는 벡터/행렬의 Shape은 (a, d)가 된다.\n",
    "\n",
    "<br>\n",
    "\n",
    "이 규칙에 유의하여 계산해야하며, 연산에는 @라는 기호를 사용합니다. \n",
    "파이썬에서 * 는 원소곱을 의미하며 @는 행렬-벡터곱, 행렬-행렬곱을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [-2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape : (2, 1)\n",
    "vec_x = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "# Shape : (2, 2)\n",
    "mat_a = np.array([[1, 0],\n",
    "                  [0, 1]])\n",
    "\n",
    "# Shape : (2, 2) @ (2, 1) = (2, 1)\n",
    "mat_a @ vec_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 3.5. 행렬 곱 (Matrix Multiplication)\n",
    "이제 조금 특별한 연산인 행렬곱에 대해 소개합니다. 행렬과 행렬을 곱한다는 것은 (원소곱이 아니라 행렬 단위로 곱한다는 것) 합성함수를 만드는 것과 동일합니다. 변환에 변환을 적용하는 것은 함수에 함수를 적용하는 것과 동일한 이치이기 때문입니다.\n",
    "<br><br>\n",
    "\n",
    "여기에서 두가지 변환을 소개하겠습니다. 첫번째는 회전(Rotation)입니다. 여기서는 반시계방향으로 90도 회전해보겠습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/51.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "회전하고나면 $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$이 되고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}$이 됩니다. 따라서 이 변환은 $\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$이 됩니다.\n",
    "<br><br>\n",
    "\n",
    "두번째는 기울이기(Shear)입니다. \n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/52.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "회전하고나면 $\\hat{i}$는 그대로 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$이고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$이 됩니다. 따라서 이 변환은 $\\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$이 됩니다. 이 두 행렬을 $\\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$ @ $\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$과 같이 행렬 곱하면 어떻게 될까요? 정답은 두 연산을 각각 실행하는 것이 됩니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/54.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "합성된 변환을 계산하면 아래처럼 계산할 수 있는데요. 각각 $\\hat{i}$와 $\\hat{j}$가 $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$과 $\\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}$으로 이동했기 때문에 합성 변환에 대한 행렬은 $\\begin{bmatrix} 1 & 1 \\\\ -1 & 0 \\end{bmatrix}$이 됩니다. 그리고 이 변환은 이전의 두 변환과는 다른 새로운 변환이 됩니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/55.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "만약 새로운 벡터가 이 변환에 적용된다면, 아래처럼 순서대로 두개의 행렬을 차례로 수행하게 되고, 이는 두 변환이 하나의 변환으로 합성된 것과 동일한 효과를 줍니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/56.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "행렬을 곱하는 것은 순서가 매우 중요합니다. 언제나, 오른쪽 변환이 먼저 수행되며, 그리고 왼쪽 변환이 수행됩니다. 수치적으로 행렬곱을 표현하면 다음과 같습니다. 가장 먼저 $\\hat{i}$가 움직일 곳을 찾습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/57.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "오른쪽 행렬이 더 먼저 적용되는 행렬이므로, 오른쪽 행렬의 왼쪽 두개 원소를 $\\hat{i}$로 생각하고 이 왼쪽 벡터가 어디로 변환될지 계산하면 아래와 같습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/58.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그리고 나서 $\\hat{j}$가 움직일 곳을 찾습니다. \n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/59.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그 뒤, 오른쪽 행렬의 오른쪽 두개 원소를 $\\hat{j}$로 생각하고 이 오른쪽 벡터가 어디로 변환될지 계산하면 아래와 같습니다.\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/60.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이렇게 계산한 결과는 여러분이 기존에 아래처럼 계산한 결과와 동일하며, 실제로는 이 계산과정을 간단하게 마치 공식처럼 풀어낸 것입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/61.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이제 numpy를 이용해 계산해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1],\n",
       "       [ 1,  0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shear = np.array([[1, 1], \n",
    "                  [0, 1]])\n",
    "\n",
    "rotation = np.array([[0, -1], \n",
    "                     [1, 0]])\n",
    "\n",
    "new_transform = shear @ rotation\n",
    "\n",
    "new_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = np.array([[2], \n",
    "                  [1]])\n",
    "\n",
    "new_vec_a = new_transform @ vec_a\n",
    "# shear와 반시계방향 90도 rotation 적용\n",
    "\n",
    "new_vec_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "마찬가지로 다양한 Shape의 행렬을 계산할 수 있습니다. 이 때 반드시 Shape 규칙을 따르게 됩니다. (Shape 규칙은 굉장히 중요합니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  8, 11, 14, 17],\n",
       "       [ 8, 13, 18, 23, 28],\n",
       "       [11, 18, 25, 32, 39]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape = (3, 2)\n",
    "mat_a = np.array([[1, 2], \n",
    "                  [2, 3], \n",
    "                  [3, 4]])\n",
    "\n",
    "# Shape = (2, 5)\n",
    "mat_b = np.array([[1, 2, 3, 4, 5], \n",
    "                  [2, 3, 4, 5, 6]])\n",
    "\n",
    "# Shape = (3, 2) @ (2, 5) = (3, 5)\n",
    "mat_a @ mat_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "한 가지 중요한 사항은 행렬곱은 교환법칙이 성립하지 않는다는 것입니다. A @ B와 B @ A가 같지 않습니다. 왜 그런지는 매우 단순한데, 순서를 바꿔서 움직이면 변환 결과가 달라지기 때문입니다. 만약 Shear를 먼저한다면 아래 처럼 움직입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/62.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그러나 우리가 rotate 먼저 한다면 아래처럼 움직입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/63.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "두 결과가 매우 상이한데, 이는 매우 당연한 것입니다. 때문에 행렬을 곱할 때는 순서를 주의해줘야합니다. 회전 후 기울인 것과 기울이고 회전한 것의 결과가 다르기 때문이죠."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
