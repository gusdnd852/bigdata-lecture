{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAmcf-rGkr4y"
   },
   "source": [
    "# 03. Seq2Seq과 어텐션 메커니즘\n",
    "> 기계번역에 사용되는 Seq2Seq 알고리즘과 LSTM의 능력을 더욱 끌어올려줄 어텐션 메커니즘에 대해 알아봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 7]\n",
    "- permalink: /attention\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgsI1njRkr4z"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1. Seq2Seq 알고리즘\n",
    "\n",
    "seq2seq는 번역기에서 대표적으로 사용되는 모델입니다. 앞으로의 설명 방식은 내부가 보이지 않는 커다란 블랙 박스에서 점차적으로 확대해가는 방식으로 설명합니다. 참고로 여기서 설명하는 내용의 대부분은 RNN 챕터에서 언급한 내용들입니다. 단지 이것을 가지고 어떻게 조립했느냐에 따라서 seq2seq라는 구조가 만들어집니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/%EC%8B%9C%ED%80%80%EC%8A%A4%ED%88%AC%EC%8B%9C%ED%80%80%EC%8A%A4.PNG)\n",
    "\n",
    "위의 그림은 seq2seq 모델로 만들어진 번역기가 'I am a student'라는 영어 문장을 입력받아서, 'je suis étudiant'라는 프랑스 문장을 출력하는 모습을 보여줍니다. 그렇다면, seq2seq 모델 내부의 모습은 어떻게 구성되었을까요?\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/seq2seq%EB%AA%A8%EB%8D%B811.PNG)\n",
    "\n",
    "seq2seq는 크게 두 개로 구성된 아키텍처로 구성되는데, 바로 인코더와 디코더입니다. 인코더는 입력 문장의 모든 단어들을 순차적으로 입력받은 뒤에 마지막에 이 모든 단어 정보들을 압축해서 하나의 벡터로 만드는데, 이를 컨텍스트 벡터(context vector)라고 합니다. 입력 문장의 정보가 하나의 컨텍스트 벡터로 모두 압축되면 인코더는 컨텍스트 벡터를 디코더로 전송합니다. 디코더는 컨텍스트 벡터를 받아서 번역된 단어를 한 개씩 순차적으로 출력합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%B2%A1%ED%84%B0.PNG)\n",
    "\n",
    "컨텍스트 벡터에 대해서는 뒤에서 다시 언급하겠습니다. 위의 그림에서는 컨텍스트 벡터를 4의 사이즈로 표현하였지만, 실제 현업에서 사용되는 seq2seq 모델에서는 보통 수백 이상의 차원을 갖고있습니다. 이제 인코더와 디코더의 내부를 좀 더 확대해보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)\n",
    "\n",
    "인코더 아키텍처와 디코더 아키텍처의 내부는 사실 두 개의 RNN 아키텍처 입니다. 입력 문장을 받는 RNN 셀을 인코더라고 하고, 출력 문장을 출력하는 RNN 셀을 디코더라고 합니다. 이번 챕터에서는 인코더의 RNN 셀을 주황색으로, 디코더의 RNN 셀을 초록색으로 표현합니다. 물론, 성능 문제로 인해 실제로는 바닐라 RNN이 아니라 LSTM 셀로 구성됩니다. 우선 인코더를 자세히보면, 입력 문장은 단어 토큰화를 통해서 단어 단위로 쪼개지고 단어 토큰 각각은 RNN 셀의 각 시점의 입력이 됩니다. 인코더 RNN 셀은 모든 단어를 입력받은 뒤에 인코더 RNN 셀의 마지막 시점의 은닉 상태를 디코더 RNN 셀로 넘겨주는데 이를 컨텍스트 벡터라고 합니다. 컨텍스트 벡터는 디코더 RNN 셀의 첫번째 은닉 상태로 사용됩니다.\n",
    "<br><br>\n",
    "\n",
    "디코더는 초기 입력으로 문장의 시작을 의미하는 심볼 <sos>(start of sentence)가 들어갑니다. 디코더는 <sos>가 입력되면, 다음에 등장할 확률이 높은 단어를 예측합니다. 첫번째 시점(time step)의 디코더 RNN 셀은 다음에 등장할 단어로 je를 예측하였습니다. 첫번째 시점의 디코더 RNN 셀은 예측된 단어 je를 다음 시점의 RNN 셀의 입력으로 입력합니다. 그리고 두번째 시점의 디코더 RNN 셀은 입력된 단어 je로부터 다시 다음에 올 단어인 suis를 예측하고, 또 다시 이것을 다음 시점의 RNN 셀의 입력으로 보냅니다. 디코더는 이런 식으로 기본적으로 다음에 올 단어를 예측하고, 그 예측한 단어를 다음 시점의 RNN 셀의 입력으로 넣는 행위를 반복합니다. 이 행위는 문장의 끝을 의미하는 심볼인 <eos>가 다음 단어로 예측될 때까지 반복됩니다. 지금 설명하는 것은 테스트 과정 동안의 이야기입니다.\n",
    "<br><br>\n",
    "\n",
    "seq2seq는 훈련 과정과 테스트 과정(또는 실제 번역기를 사람이 쓸 때)의 작동 방식이 조금 다릅니다. 훈련 과정에서는 디코더에게 인코더가 보낸 컨텍스트 벡터와 실제 정답인 상황인 <sos> je suis étudiant를 입력 받았을 때, je suis étudiant <eos>가 나와야 된다고 정답을 알려주면서 훈련합니다. 반면 테스트 과정에서는 앞서 설명한 과정과 같이 디코더는 오직 컨텍스트 벡터와 <sos>만을 입력으로 받은 후에 다음에 올 단어를 예측하고, 그 단어를 다음 시점의 RNN 셀의 입력으로 넣는 행위를 반복합니다. 즉, 앞서 설명한 과정과 위의 그림은 테스트 과정에 해당됩니다. 이번에는 입, 출력에 쓰이는 단어 토큰들이 있는 부분을 좀 더 확대해보겠습니다.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQsxv-02kr40"
   },
   "source": [
    "![](https://wikidocs.net/images/page/24996/%EB%8B%A8%EC%96%B4%ED%86%A0%ED%81%B0%EB%93%A4%EC%9D%B4.PNG)\n",
    "\n",
    "기계는 텍스트보다 숫자를 잘 처리합니다. 그리고 자연어 처리에서 텍스트를 벡터로 바꾸는 방법으로 워드 임베딩(10챕터 참고)이 사용된다고 설명한 바 있습니다. 즉, seq2seq에서 사용되는 모든 단어들은 워드 임베딩을 통해 임베딩 벡터로서 표현된 임베딩 벡터입니다. 위 그림은 모든 단어에 대해서 임베딩 과정을 거치게 하는 단계인 임베딩 층(embedding layer)의 모습을 보여줍니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/%EC%9E%84%EB%B2%A0%EB%94%A9%EB%B2%A1%ED%84%B0.PNG)\n",
    "\n",
    "예를 들어 I, am, a, student라는 단어들에 대한 임베딩 벡터는 위와 같은 모습을 가집니다. 여기서는 그림으로 표현하고자 사이즈를 4로 하였지만, 보통 실제 임베딩 벡터는 수백 개의 차원을 가질 수 있습니다. 이제 RNN 셀에 대해서 확대해보겠습니다.\n",
    "<br><br>\n",
    "\n",
    "이미 RNN에 대해서 배운 적이 있지만, 다시 복습을 해보도록 하겠습니다. 하나의 RNN 셀은 각각의 시점(time step)마다 두 개의 입력을 받습니다. (이해가 되지 않는다면, RNN 챕터를 다시 참고하세요.)\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/rnn%EA%B7%BC%ED%99%A9.PNG)\n",
    "\n",
    "현재 시점(time step)을 t라고 할 때, RNN 셀은 t-1에서의 은닉 상태와 t에서의 입력 벡터를 입력으로 받고, t에서의 은닉 상태를 만듭니다. 이때 t에서의 은닉 상태는 바로 위에 또 다른 은닉층이나 출력층이 존재할 경우에는 위의 층으로 보내거나, 필요없으면 값을 무시할 수 있습니다. 그리고 RNN 셀은 다음 시점에 해당하는 t+1의 RNN 셀의 입력으로 현재 t에서의 은닉 상태를 입력으로 보냅니다.\n",
    "<br><br>\n",
    "\n",
    "RNN 챕터에서도 언급했지만, 이런 구조에서 현재 시점 t에서의 은닉 상태는 과거 시점의 동일한 RNN 셀에서의 모든 은닉 상태의 값들의 영향을 누적해서 받아온 값이라고 할 수 있습니다. 그렇기 때문에 앞서 우리가 언급했던 컨텍스트 벡터는 사실 인코더에서의 마지막 RNN 셀의 은닉 상태값을 말하는 것이며, 이는 입력 문장의 모든 단어 토큰들의 정보를 요약해서 담고있다고 할 수 있습니다.\n",
    "<br><br>\n",
    "\n",
    "디코더는 인코더의 마지막 RNN 셀의 은닉 상태인 컨텍스트 벡터를 첫번째 은닉 상태의 값으로 사용합니다. 디코더의 첫번째 RNN 셀은 이 첫번째 은닉 상태의 값과, 현재 t에서의 입력값인 <sos>로부터, 다음에 등장할 단어를 예측합니다. 그리고 이 예측된 단어는 다음 시점인 t+1 RNN에서의 입력값이 되고, 이 t+1에서의 RNN 또한 이 입력값과 t에서의 은닉 상태로부터 t+1에서의 출력 벡터. 즉, 또 다시 다음에 등장할 단어를 예측하게 될 것입니다. 이제 디코더가 다음에 등장할 단어를 예측하는 부분을 확대해보도록 하겠습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/24996/decodernextwordprediction.PNG)\n",
    "\n",
    "출력 단어로 나올 수 있는 단어들은 다양한 단어들이 있습니다. seq2seq 모델은 선택될 수 있는 모든 단어들로부터 하나의 단어를 골라서 예측해야 합니다. 이를 예측하기 위해서 쓸 수 있는 함수로는 뭐가 있을까요? 바로 소프트맥스 함수입니다. 디코더에서 각 시점(time step)의 RNN 셀에서 출력 벡터가 나오면, 해당 벡터는 소프트맥스 함수를 통해 출력 시퀀스의 각 단어별 확률값을 반환하고, 디코더는 출력 단어를 결정합니다.\n",
    "<br><br>\n",
    "\n",
    "지금까지 가장 기본적인 seq2seq에 대해서 배워보았습니다. 사실 seq2seq는 어떻게 구현하느냐에 따라서 충분히 더 복잡해질 수 있습니다. 컨텍스트 벡터를 디코더의 초기 은닉 상태로만 사용할 수도 있고, 거기서 더 나아가 컨텍스트 벡터를 디코더가 단어를 예측하는 매 시점마다 하나의 입력으로 사용할 수도 있으며 거기서 더 나아가면 어텐션 메커니즘이라는 방법을 통해 지금 알고있는 컨텍스트 벡터보다 더욱 문맥을 반영할 수 있는 컨텍스트 벡터를 구하여 매 시점마다 하나의 입력으로 사용할 수도 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YymPgLKHkr41"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2. 어텐션(Attention)의 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8viPvLHAkr41"
   },
   "source": [
    "seq2seq 모델은 인코더에서 입력 시퀀스를 컨텍스트 벡터라는 하나의 고정된 크기의 벡터 표현으로 압축하고, 디코더는 이 컨텍스트 벡터를 통해서 출력 시퀀스를 만들어냈습니다. 하지만 이러한 RNN에 기반한 seq2seq 모델에는 크게 두 가지 문제가 있습니다.\n",
    "\n",
    "- 첫째, 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생합니다.\n",
    "- 둘째, RNN의 고질적인 문제인 기울기 소실(Vanishing Gradient) 문제가 존재합니다.\n",
    "<br><br>\n",
    "\n",
    "즉, 결국 이는 기계 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상으로 나타났습니다. 이를 위한 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위한 등장한 기법인 어텐션(attention)을 소개합니다.\n",
    "어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDoXi4szkr42"
   },
   "source": [
    "<br> \n",
    "\n",
    "### 3. 어텐션 함수(Attention Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyblCdmAkr43"
   },
   "source": [
    "어텐션 메커니즘을 언급하기 전에 컴퓨터공학의 많은 분야에서 사용되는 Key-Value로 구성되는 자료형에 대해서 잠깐 언급하겠습니다. 가령, 이 책의 주 언어로 사용되는 파이썬에도 Key-Value로 구성되는 자료형인 딕셔너리(Dict) 자료형이 존재합니다. 파이썬의 딕셔너리 자료형은 키(Key)와 값(Value)이라는 두 개의 쌍으로 구성되는데, 키를 통해서 맵핑된 값을 찾아낼 수 있다는 특징을 갖고있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1809,
     "status": "ok",
     "timestamp": 1596042974863,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "aiCy2WxWkr43"
   },
   "outputs": [],
   "source": [
    "# 파이썬의 딕셔너리 자료형을 선언\n",
    "# 키(Key) : 값(value)의 형식으로 키와 값의 쌍(Pair)을 선언한다.\n",
    "dicts = {\"2017\" : \"Transformer\", \"2018\" : \"BERT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1794,
     "status": "ok",
     "timestamp": 1596042974864,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "pMZ2exvBkr47",
    "outputId": "2351d4ca-5a72-404c-c143-39155132b36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer\n"
     ]
    }
   ],
   "source": [
    "print(dicts[\"2017\"]) #2017이라는 키에 해당되는 값을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1776,
     "status": "ok",
     "timestamp": 1596042974865,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "4KQIHNLVkr4-",
    "outputId": "f8b96e09-0086-4845-9575-c3f73557b354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n"
     ]
    }
   ],
   "source": [
    "print(dicts[\"2018\"]) #2018이라는 키에 해당되는 값을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nY2bLOyckr5B"
   },
   "source": [
    "Key-Value 자료형에 대한 이해를 가지고, 어텐션 함수에 대해서 설명해보겠습니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)\n",
    "\n",
    "어텐션을 함수로 표현하면 주로 다음과 같이 표현됩니다. \n",
    "<br>\n",
    "\n",
    "**Attention(Q, K, V) = Attention Value**\n",
    "<br>\n",
    "\n",
    "어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다. 그리고 구해낸 이 유사도를 키와 맵핑되어있는 각각의 '값(Value)'에 반영해줍니다. 그리고 유사도가 반영된 '값(Value)'을 모두 더해서 리턴합니다. 여기서는 이를 어텐션 값(Attention Value)이라고 하겠습니다.\n",
    "<br><br>\n",
    "\n",
    "지금부터 배우게 되는 seq2seq + 어텐션 모델에서 Q, K, V에 해당되는 각각의 Query, Keys, Values는 각각 다음과 같습니다.\n",
    "\n",
    "- Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "- K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "- V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "\n",
    "이제 매우 간소화 된 어텐션 예제를 통해 어텐션을 이해해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlMnaPGwkr5B"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4. 닷-프로덕트 어텐션(Dot-Product Attention)\n",
    "\n",
    "어텐션은 다양한 종류가 있는데 그 중에서도 가장 수식적으로 이해하기 쉽게 수식을 적용한 닷-프로덕트 어텐션(Dot-Product Attention)을 통해 어텐션을 이해해보도록 하겠습니다. seq2seq에서 사용되는 어텐션 중에서 닷-프로덕트 어텐션과 다른 어텐션의 차이는 주로 중간 수식의 차이로 메커니즘 자체는 거의 유사합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG)\n",
    "\n",
    " 그림은 디코더의 세번째 LSTM 셀에서 출력 단어를 예측할 때, 어텐션 메커니즘을 사용하는 모습을 보여줍니다. 디코더의 첫번째, 두번째 LSTM 셀은 이미 어텐션 메커니즘을 통해 je와 suis를 예측하는 과정을 거쳤다고 가정합니다. 어텐션 메커니즘에 대해 상세히 설명하기 전에 위의 그림을 통해 전체적인 감만 우선 잡고 들어가보겠습니다. 디코더의 세번째 LSTM 셀은 출력 단어를 예측하기 위해서 인코더의 모든 입력 단어들의 정보를 다시 한번 참고하고자 합니다. 중간 과정에 대한 설명은 현재는 생략하고 여기서 주목할 것은 인코더의 소프트맥스 함수입니다.\n",
    "<br><br>\n",
    "\n",
    "소프트맥스 함수를 통해 나온 결과값은 I, am, a, student 단어 각각이 출력 단어를 예측할 때 얼마나 도움이 되는지의 정도를 수치화한 값입니다. 위의 그림에서는 빨간 직사각형의 크기로 소프트맥스 함수의 결과값의 크기를 표현했습니다. 직사각형의 크기가 클 수록 도움이 되는 정도의 크기가 큽니다. 각 입력 단어가 디코더의 예측에 도움이 되는 정도가 수치화하여 측정되면 이를 하나의 정보로 담아서 디코더로 전송됩니다. 위의 그림에서는 초록색 삼각형이 이에 해당됩니다. 결과적으로, 디코더는 출력 단어를 더 정확하게 예측할 확률이 높아집니다. 이제 어텐션 메커니즘에 대한 전체적인 감을 잡았으면 어텐션 메커니즘에 대해 상세히 알아보겠습니다.\n",
    "<br><br>\n",
    "\n",
    "#### 4.1. 어텐션 스코어를 구한다\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG)\n",
    "\n",
    "인코더의 시점(time step)을 각각 1, 2, ... N이라고 하였을 때 인코더의 은닉 상태(hidden state)를 각각 h1, h2, ... hN라고 합시다. 디코더의 현재 시점(time step) t에서의 디코더의 은닉 상태(hidden state)를 st라고 합시다. 또한 여기서는 인코더의 은닉 상태와 디코더의 은닉 상태의 차원이 같다고 가정합니다. 위의 그림의 경우에는 인코더의 은닉 상태와 디코더의 은닉 상태가 동일하게 차원이 4입니다.\n",
    "<br><br>\n",
    "\n",
    "어텐션 메커니즘의 첫 걸음인 어텐션 스코어(Attention score)에 대해서 배우기전에, 이전 챕터에서 배웠던 디코더의 현재 시점 t에서 필요한 입력값을 다시 상기해보겠습니다. 시점 t에서 출력 단어를 예측하기 위해서 디코더의 셀은 두 개의 입력값을 필요로 하는데, 바로 이전 시점인 t-1의 은닉 상태와 이전 시점 t-1에 나온 출력 단어입니다.\n",
    "<br><br>\n",
    "\n",
    "그런데 어텐션 메커니즘에서는 출력 단어 예측에 또 다른 값을 필요로 하는데 바로 어텐션 값(Attention Value)이라는 새로운 값입니다. t번째 단어를 예측하기 위한 어텐션 값을 at이라고 정의하겠습니다.\n",
    "<br><br>\n",
    "\n",
    "어텐션 값이라는 새로운 개념이 등장한 만큼, 어텐션 값이 현재 시점 t에서의 출력 예측에 구체적으로 어떻게 반영되는지는 뒤에서 설명하겠습니다. 지금부터 배우는 모든 과정은 at를 구하기 위한 여정입니다. 그리고 그 여정의 첫 걸음은 바로 어텐션 스코어(Attention Score)를 구하는 일입니다. 어텐션 스코어란 현재 디코더의 시점 t에서 단어를 예측하기 위해, 인코더의 모든 은닉 상태 각각이 디코더의 현 시점의 은닉 상태 st와 얼마나 유사한지를 판단하는 스코어값입니다.\n",
    "<br><br>\n",
    "\n",
    "닷-프로덕트 어텐션에서는 이 스코어 값을 구하기 위해 st를 전치(transpose)하고 각 은닉 상태와 내적(dot product)을 수행합니다. 즉, 모든 어텐션 스코어 값은 스칼라입니다. 예를 들어 st과 인코더의 i번째 은닉 상태의 어텐션 스코어의 계산 방법은 아래와 같습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/i%EB%B2%88%EC%A7%B8%EC%96%B4%ED%85%90%EC%85%98%EC%8A%A4%EC%BD%94%EC%96%B4_final.PNG)\n",
    "\n",
    "어텐션 스코어 함수를 정의해보면 다음과 같습니다.\n",
    "<br><br>\n",
    "\n",
    "$score(s_t, h_i)=s^T_t \\cdot h_i$\n",
    "\n",
    "$s_t$와 인코더의 모든 은닉 상태의 어텐션 스코어의 모음값을 $e^t$라고 정의하겠습니다. $e^t$의 수식은 다음과 같습니다.\n",
    "\n",
    "- $e^t$=$[s^T_t \\cdot h1,...,s^T_t \\cdot h_N]$\n",
    "<br><br>\n",
    "\n",
    "#### 4.2. 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG)\n",
    "\n",
    "$e^t$에 소프트맥스 함수를 적용하여, 모든 값을 합하면 1이 되는 확률 분포를 얻어냅니다. 이를 어텐션 분포(Attention Distribution)라고 하며, 각각의 값은 어텐션 가중치(Attention Weight)라고 합니다. 예를 들어 소프트맥스 함수를 적용하여 얻은 출력값인 I, am, a, student의 어텐션 가중치를 각각 0.1, 0.4, 0.1, 0.4라고 합시다. 이들의 합은 1입니다. 위의 그림은 각 인코더의 은닉 상태에서의 어텐션 가중치의 크기를 직사각형의 크기를 통해 시각화하였습니다. 즉, 어텐션 가중치가 클수록 직사각형이 큽니다.\n",
    "<br><br>\n",
    "\n",
    "디코더의 시점 $t$에서의 어텐션 가중치의 모음값인 어텐션 분포를 $\\alpha^t$이라고 할 때, $\\alpha^t$을 식으로 정의하면 다음과 같습니다.\n",
    "\n",
    "$\\alpha^t = softmax(e^t)$\n",
    "<br><br>\n",
    "\n",
    "#### 4.3 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG)\n",
    "\n",
    "이제 지금까지 준비해온 정보들을 하나로 합치는 단계입니다. 어텐션의 최종 결과값을 얻기 위해서 각 인코더의 은닉 상태와 어텐션 가중치값들을 곱하고, 최종적으로 모두 더합니다. 요약하면 가중합(Weighted Sum)을 한다고 말할 수도 있겠습니다. 아래는 어텐션의 최종 결과. 즉, 어텐션 함수의 출력값인 어텐션 값(Attention Value) at에 대한 식을 보여줍니다.\n",
    "\n",
    "$$\n",
    "a_t = \\sum_i \\alpha^t_i h_i\n",
    "$$\n",
    "\n",
    "이러한 어텐션 값 at은 종종 인코더의 문맥을 포함하고 있다고하여, 컨텍스트 벡터(context vector)라고도 불립니다. 앞서 배운 가장 기본적인 seq2seq에서는 인코더의 마지막 은닉 상태를 컨텍스트 벡터라고 부르는 것과 대조됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biBPLw5Mkr5C"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "#### 4.4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate)\n",
    "\n",
    "제 어텐션 함수의 최종값인 어텐션 값 $a_t$을 구했습니다. 앞서 어텐션 메커니즘이 들어간 t시점의 은닉 상태를 구하는 방법의 식으로 다음과 같은 식을 소개한 바 있습니다. 사실 어텐션 값이 구해지면 어텐션 메커니즘은 $a_t$를 $s_t$와 결합(concatenate)하여 하나의 벡터로 만드는 작업을 수행합니다. 이를 $v_t$라고 정의해보겠습니다. 그리고 이 $v_t$를 $\\hat{y}$ 예측 연산의 입력으로 사용하므로서 인코더로부터 얻은 정보를 활용하여 $\\hat{y}$를 좀 더 잘 예측할 수 있게 됩니다. 이것이 어텐션 메커니즘의 핵심입니다.\n",
    "<br><br>\n",
    "\n",
    "#### 4.5. 출력층 연산의 입력이 되는 s~t를 계산합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22893/st.PNG)\n",
    "\n",
    "논문에서는 $v_t$를 바로 출력층으로 보내기 전에 신경망 연산을 한 번 더 추가하였습니다. 가중치 행렬과 곱한 후에 하이퍼볼릭탄젠트 함수를 지나도록 하여 출력층 연산을 위한 새로운 벡터인 $\\hat{s}_t$를 얻습니다. 어텐션 메커니즘을 사용하지 않는 seq2seq에서는 출력층의 입력이 $t$시점의 은닉 상태인 $s_t$였던 반면, 어텐션 메커니즘에서는 출력층의 입력이 $\\hat{s}_t$가 되는 셈입니다.\n",
    "\n",
    "이를 식으로 표현하면 다음과 같습니다. 식에서 $W_c$는 학습 가능한 가중치 행렬, $b_c$는 편향입니다. 그림에서 편향은 생략했습니다.\n",
    "\n",
    "$\\hat{s}_t = tanh(W_c[\\alpha_t;s_t] + b_c)$\n",
    "<br><br>\n",
    "\n",
    "#### 4.6. 계산한 $\\hat{s}_t$를 출력층의 입력으로 사용합니다.\n",
    "\n",
    "$\\hat{s}_t$를 출력층의 입력으로 사용하여 예측 벡터를 얻습니다.\n",
    "\n",
    "$\\hat{y}_t = Softmax(W_y \\hat{s}_t + b_y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmB0dWmhkr5C"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "### 5. Word-Level 번역기 만들기\n",
    "\n",
    "이번 챕터에서는 단어 레벨(Word-level)의 기계 번역기를 만들어봅시다. 이번 챕터는 이전 챕터의 이론적인 내용을 이해했다는 가정 하에 모델에 대한 설명을 자세하게 하지 않겠습니다. 아래의 코드에는 어텐션 메커니즘은 적용되어있지 않고 바닐라 Seq2Seq 모델로 구현하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYIVzC_Kkr5C"
   },
   "source": [
    "#### 5.1. 데이터 로드 및 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1596043789945,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "4F_TcRJpkr5D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKszo5ITkr5F"
   },
   "source": [
    "데이터를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1596043793555,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "_Nhr9hT4kr5G"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'sample_data/fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path + '/sample_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5gLE2w5kr5I"
   },
   "source": [
    "이번 챕터에서는 총 50,000개의 샘플을 사용할 예정입니다. 이 값을 변수에 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1596043800623,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "KTlRF9_Hkr5J"
   },
   "outputs": [],
   "source": [
    "num_samples = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgAXi25ykr5L"
   },
   "source": [
    "전처리 함수들을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1596043802827,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "R9E6Rpcdkr5L"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1596043804322,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "ehrYXdR_kr5O"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5YnhC14kr5Q"
   },
   "source": [
    "구현한 전처리 함수들을 임의의 문장을 입력으로 테스트해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1596043806223,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "_yJL965Rkr5Q",
    "outputId": "24ee6377-6012-4cac-e28a-4065612f6f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCpxZbDbkr5T"
   },
   "source": [
    "전체 데이터에서 50,000개의 샘플만 불러오되, 모든 전처리를 수행하는 함수를 만듭니다. 입력 시퀀스에는 시작을 의미하는 토큰인 <sos>를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 <eos>를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1596043809153,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "owvDbn5mkr5T"
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"./sample_data/fra.txt\", \"r\", encoding='utf-8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dykopk-Pkr5V"
   },
   "source": [
    "이렇게 얻은 3개의 데이터셋은 인코더의 입력, 디코더의 입력, 디코더의 실제값을 상위 5개 샘플만 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2295,
     "status": "ok",
     "timestamp": 1596043814153,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "6CQfOo8Okr5W",
    "outputId": "eac9b222-ea61-4f43-e0df-dc97c737a82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtPIkD-5kr5Y"
   },
   "source": [
    "이제 텐서플로우 토크나이저를 통해 단어 집합을 생성하고, 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정을 거칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1688,
     "status": "ok",
     "timestamp": 1596043817512,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "Z3RH6Acfkr5Y"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QdHKXIrkr5f"
   },
   "source": [
    "문장마다 단어의 수가 다르면 텐서로 만들수가 없습니다. 때문에 단어의 길이를 통일시켜주기 위해 길이가 짧은 문장은 뒤에 영벡터(패딩)을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1596043820841,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "XlQMJS7okr5f"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5CT5u-nkr5h"
   },
   "source": [
    "이렇게 얻은 데이터의 크기(shape)를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1596043825455,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "of9YJxiakr5i",
    "outputId": "1f641367-ea34-454d-eb05-73bb56d12448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 9)\n",
      "(50000, 17)\n",
      "(50000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J6-BGySUkr5k"
   },
   "source": [
    "샘플은 총 50,000개 존재하며 영어 문장의 길이는 8, 프랑스어 문장의 길이는 16입니다. 단어 집합의 크기를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1596043828447,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "lTPOY0Gakr5l",
    "outputId": "39ef7221-cc38-493a-88da-0a75abea98ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 5853, 프랑스어 단어 집합의 크기 : 10113\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30XKCRn8kr5n"
   },
   "source": [
    "단어 집합의 크기는 각각 5853개와 10113개입니다. 단어로부터 정수를 얻는 딕셔너리와 정수로부터 단어를 얻는 딕셔너리를 각각 만들어줍니다. 이들은 훈련을 마치고 예측 과정과 실제값과 결과를 비교하는 경우에 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1596043849113,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "kcjY5V1bkr5n"
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpM3MGJTkr5p"
   },
   "source": [
    "이제 테스트 데이터를 분리할 차례입니다. 테스트 데이터를 분리하기 전에, 적절한 분포를 갖도록 데이터를 섞어주는 과정을 진행합니다. 이를 위해서 우선 순서가 섞인 정수 시퀀스 리스트를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1596043851842,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "HhQjHYlAkr5p",
    "outputId": "b5f1210a-60b8-4833-844a-bfe3d3331110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36828 41203 35526 ...  9767 30681 29885]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEXqNsEikr5r"
   },
   "source": [
    "이를 데이터셋의 순서로 지정해주면 샘플들이 기존 순서와 다른 순서로 섞이게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1596043853601,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "yTBWFm8qkr5r"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLZO2cKBkr5t"
   },
   "source": [
    "임의로 15000번째 샘플을 출력해봅시다. 이때, decoder_input과 decoder_target은 데이터의 구조상으로 앞에 붙은 <sos> 토큰과 뒤에 붙은 <eos>을 제외하면 동일한 정수 시퀀스를 가져야하므로 이를 확인해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1596043856014,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "_GSxuUNTkr5t",
    "outputId": "32517470-2ee3-45e0-8e98-43c9d8b1959b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24,   9,  32, 215,   1,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1596043857874,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "BW0ciR1Jkr5v",
    "outputId": "bb4c9e9b-9431-4600-e74d-d7da09fe6416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  13, 135,   9, 541,  18,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1596043859426,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "bCfJNHs8kr5x",
    "outputId": "61f42926-91a3-4790-c23f-10287ae30778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13, 135,   9, 541,  18,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6n37rorOkr5y"
   },
   "source": [
    "이제 훈련 데이터의 10%를 테스트 데이터로 분리하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1596043865409,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "gUB4BzAckr5y",
    "outputId": "ba03dfa7-bb7c-466e-b5bd-0acc60882452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(50000 * 0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jgJHh8bkr50"
   },
   "source": [
    "50000개의 10%에 해당되는 5000개의 데이터를 테스트 데이터로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1596043877646,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "AlWsRv-4kr50"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLiVPnh7kr52"
   },
   "source": [
    "훈련 데이터와 테스트 데이터의 크기(shape)를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1596043880620,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "q55PMJ0Rkr52",
    "outputId": "ed15a577-eeb4-4caf-e9a1-de997fea7ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 9)\n",
      "(45000, 17)\n",
      "(45000, 17)\n",
      "(5000, 9)\n",
      "(5000, 17)\n",
      "(5000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVVjk49Ikr54"
   },
   "source": [
    "훈련 데이터의 샘플은 45000개, 테스트 데이터의 샘플은 5000개가 존재합니다. 이제 모델을 설계합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TukWI2Gkkr54"
   },
   "source": [
    "#### 5.2. 기계 번역기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bv_687orkr55"
   },
   "source": [
    "모델 설계를 위해 필요한 도구들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1596043892490,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "BgapDxcvkr55"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0ZZf9swkr57"
   },
   "source": [
    "임베딩 벡터와 LSTM의 은닉 상태의 크기를 특정 크기로 고정하고자 합니다. 여기서는 50을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1596043894345,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "E74KUwwVkr57"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUFT_6sgkr59"
   },
   "source": [
    "인코더를 설계합니다. Masking은 패딩 토큰인 숫자 0의 경우에는 연산을 제외하는 역할을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1596043896847,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "bpgmsLkkkr59"
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1392,
     "status": "ok",
     "timestamp": 1596043899248,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "crnonFmukr5_"
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yo6f8zGykr6A"
   },
   "source": [
    "모델의 입력과 출력을 정의하므로서 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1596043901089,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "aMDl7CTTkr6B"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAVE4c97kr6C"
   },
   "source": [
    "seq2seq의 디코더는 기본적으로 각각의 시점(timestep)에 대해서 다중 클래스 분류 문제를 풀고있습니다. 매 시점마다 프랑스어 단어 집합의 크기의 선택지에서 단어를 1개 선택하여 이를 이번 시점에서 예측한 단어로 택합니다. 다중 클래스 분류 문제이므로 위의 설계에서 출력층으로 소프트맥스 함수를 사용했습니다. 현재는 원-핫 인코딩을 하지 않은 상태로, 정수 레이블에 대해서 다중 클래스 분류 문제를 풀고자 하는 경우에는 sparse_categorical_crossentropy를 사용하면 됩니다. 이는 텐서플로우에서 규정한 약속입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1596043903068,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "5fGz9PPIkr6D"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Xcq_F7Okr6E"
   },
   "source": [
    "모델의 파라미터를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1596043905097,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "ZqZdO25Zkr6F",
    "outputId": "7eeefe86-acf2-43a5-9b25-4564418ac6ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     292650      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 50)     505650      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 50)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_3 (Masking)             (None, None, 50)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50), (None,  20200       masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 50), ( 20200       masking_3[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10113)  515763      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,354,463\n",
      "Trainable params: 1,354,463\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKHoNbDhkr6G"
   },
   "source": [
    "이제 모델을 훈련합니다. 32개의 배치 크기로 총 100 에포크 학습합니다. 테스트 데이터를 검증 데이터로 사용하여 훈련이 제대로 되고있는지 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4092076,
     "status": "ok",
     "timestamp": 1596048003763,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "LheNcSl_kr6H",
    "outputId": "d756f567-b93a-4212-859e-eb8431eaa83f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 43s 31ms/step - loss: 1.9172 - acc: 0.7173 - val_loss: 1.4937 - val_acc: 0.7649\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.3954 - acc: 0.7785 - val_loss: 1.3262 - val_acc: 0.7921\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.2746 - acc: 0.7986 - val_loss: 1.2454 - val_acc: 0.8043\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1994 - acc: 0.8103 - val_loss: 1.1869 - val_acc: 0.8137\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1415 - acc: 0.8189 - val_loss: 1.1423 - val_acc: 0.8202\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0951 - acc: 0.8257 - val_loss: 1.1064 - val_acc: 0.8261\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0694 - acc: 0.8314 - val_loss: 1.0966 - val_acc: 0.8309\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0582 - acc: 0.8360 - val_loss: 1.0866 - val_acc: 0.8342\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0432 - acc: 0.8402 - val_loss: 1.0742 - val_acc: 0.8378\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0299 - acc: 0.8444 - val_loss: 1.0711 - val_acc: 0.8390\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0218 - acc: 0.8475 - val_loss: 1.0680 - val_acc: 0.8421\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0184 - acc: 0.8500 - val_loss: 1.0673 - val_acc: 0.8442\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0127 - acc: 0.8527 - val_loss: 1.0599 - val_acc: 0.8463\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9984 - acc: 0.8554 - val_loss: 1.0475 - val_acc: 0.8484\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9831 - acc: 0.8583 - val_loss: 1.0412 - val_acc: 0.8500\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9751 - acc: 0.8600 - val_loss: 1.0385 - val_acc: 0.8501\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9689 - acc: 0.8615 - val_loss: 1.0351 - val_acc: 0.8517\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9649 - acc: 0.8629 - val_loss: 1.0357 - val_acc: 0.8524\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9611 - acc: 0.8642 - val_loss: 1.0368 - val_acc: 0.8524\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9576 - acc: 0.8658 - val_loss: 1.0308 - val_acc: 0.8533\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9520 - acc: 0.8669 - val_loss: 1.0269 - val_acc: 0.8546\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9447 - acc: 0.8686 - val_loss: 1.0218 - val_acc: 0.8556\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9368 - acc: 0.8698 - val_loss: 1.0201 - val_acc: 0.8556\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9285 - acc: 0.8708 - val_loss: 1.0125 - val_acc: 0.8568\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9189 - acc: 0.8720 - val_loss: 1.0049 - val_acc: 0.8571\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9129 - acc: 0.8729 - val_loss: 1.0032 - val_acc: 0.8584\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9092 - acc: 0.8738 - val_loss: 1.0042 - val_acc: 0.8578\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9068 - acc: 0.8745 - val_loss: 1.0042 - val_acc: 0.8584\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.9047 - acc: 0.8751 - val_loss: 1.0030 - val_acc: 0.8584\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9012 - acc: 0.8757 - val_loss: 1.0084 - val_acc: 0.8580\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9001 - acc: 0.8764 - val_loss: 1.0035 - val_acc: 0.8586\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8996 - acc: 0.8768 - val_loss: 1.0079 - val_acc: 0.8582\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8994 - acc: 0.8776 - val_loss: 1.0070 - val_acc: 0.8590\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8987 - acc: 0.8780 - val_loss: 1.0070 - val_acc: 0.8588\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8979 - acc: 0.8785 - val_loss: 1.0069 - val_acc: 0.8589\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8971 - acc: 0.8789 - val_loss: 1.0079 - val_acc: 0.8592\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8955 - acc: 0.8796 - val_loss: 1.0115 - val_acc: 0.8587\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8953 - acc: 0.8799 - val_loss: 1.0120 - val_acc: 0.8583\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8939 - acc: 0.8804 - val_loss: 1.0080 - val_acc: 0.8593\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8927 - acc: 0.8809 - val_loss: 1.0100 - val_acc: 0.8584\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8915 - acc: 0.8813 - val_loss: 1.0069 - val_acc: 0.8602\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8894 - acc: 0.8818 - val_loss: 1.0083 - val_acc: 0.8599\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8876 - acc: 0.8823 - val_loss: 1.0061 - val_acc: 0.8598\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8853 - acc: 0.8827 - val_loss: 1.0047 - val_acc: 0.8598\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8832 - acc: 0.8829 - val_loss: 1.0066 - val_acc: 0.8592\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8809 - acc: 0.8837 - val_loss: 1.0101 - val_acc: 0.8587\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8782 - acc: 0.8841 - val_loss: 1.0031 - val_acc: 0.8604\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8758 - acc: 0.8845 - val_loss: 1.0058 - val_acc: 0.8596\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8733 - acc: 0.8848 - val_loss: 1.0044 - val_acc: 0.8601\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8712 - acc: 0.8851 - val_loss: 1.0036 - val_acc: 0.8590\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8687 - acc: 0.8855 - val_loss: 1.0031 - val_acc: 0.8592\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8667 - acc: 0.8860 - val_loss: 1.0028 - val_acc: 0.8592\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8649 - acc: 0.8863 - val_loss: 1.0016 - val_acc: 0.8596\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8632 - acc: 0.8865 - val_loss: 1.0030 - val_acc: 0.8593\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8616 - acc: 0.8868 - val_loss: 1.0005 - val_acc: 0.8601\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8598 - acc: 0.8874 - val_loss: 1.0003 - val_acc: 0.8608\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8580 - acc: 0.8875 - val_loss: 1.0030 - val_acc: 0.8599\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8564 - acc: 0.8879 - val_loss: 1.0045 - val_acc: 0.8590\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8548 - acc: 0.8881 - val_loss: 1.0028 - val_acc: 0.8595\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8534 - acc: 0.8884 - val_loss: 1.0050 - val_acc: 0.8596\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8520 - acc: 0.8887 - val_loss: 1.0045 - val_acc: 0.8591\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8501 - acc: 0.8891 - val_loss: 1.0038 - val_acc: 0.8593\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8489 - acc: 0.8892 - val_loss: 1.0050 - val_acc: 0.8593\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8476 - acc: 0.8894 - val_loss: 1.0058 - val_acc: 0.8590\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8465 - acc: 0.8897 - val_loss: 1.0079 - val_acc: 0.8585\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8457 - acc: 0.8899 - val_loss: 1.0075 - val_acc: 0.8587\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8447 - acc: 0.8903 - val_loss: 1.0083 - val_acc: 0.8589\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8432 - acc: 0.8904 - val_loss: 1.0073 - val_acc: 0.8591\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8418 - acc: 0.8906 - val_loss: 1.0095 - val_acc: 0.8585\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8410 - acc: 0.8907 - val_loss: 1.0103 - val_acc: 0.8583\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8399 - acc: 0.8909 - val_loss: 1.0114 - val_acc: 0.8584\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8389 - acc: 0.8910 - val_loss: 1.0132 - val_acc: 0.8580\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.8380 - acc: 0.8913 - val_loss: 1.0108 - val_acc: 0.8590\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8371 - acc: 0.8914 - val_loss: 1.0135 - val_acc: 0.8574\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8363 - acc: 0.8914 - val_loss: 1.0135 - val_acc: 0.8578\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8353 - acc: 0.8918 - val_loss: 1.0130 - val_acc: 0.8575\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8346 - acc: 0.8918 - val_loss: 1.0162 - val_acc: 0.8569\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8343 - acc: 0.8919 - val_loss: 1.0187 - val_acc: 0.8569\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8333 - acc: 0.8921 - val_loss: 1.0242 - val_acc: 0.8556\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8328 - acc: 0.8921 - val_loss: 1.0164 - val_acc: 0.8575\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8311 - acc: 0.8925 - val_loss: 1.0185 - val_acc: 0.8567\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8307 - acc: 0.8927 - val_loss: 1.0218 - val_acc: 0.8565\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8301 - acc: 0.8926 - val_loss: 1.0196 - val_acc: 0.8569\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8288 - acc: 0.8928 - val_loss: 1.0245 - val_acc: 0.8551\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8287 - acc: 0.8929 - val_loss: 1.0215 - val_acc: 0.8566\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.8277 - acc: 0.8929 - val_loss: 1.0202 - val_acc: 0.8567\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8272 - acc: 0.8932 - val_loss: 1.0219 - val_acc: 0.8561\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.8265 - acc: 0.8933 - val_loss: 1.0233 - val_acc: 0.8561\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8257 - acc: 0.8935 - val_loss: 1.0252 - val_acc: 0.8560\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8256 - acc: 0.8934 - val_loss: 1.0240 - val_acc: 0.8565\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8253 - acc: 0.8937 - val_loss: 1.0282 - val_acc: 0.8554\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8248 - acc: 0.8938 - val_loss: 1.0268 - val_acc: 0.8557\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8238 - acc: 0.8937 - val_loss: 1.0261 - val_acc: 0.8562\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8235 - acc: 0.8936 - val_loss: 1.0279 - val_acc: 0.8559\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8230 - acc: 0.8940 - val_loss: 1.0326 - val_acc: 0.8543\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8222 - acc: 0.8940 - val_loss: 1.0317 - val_acc: 0.8545\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8217 - acc: 0.8942 - val_loss: 1.0321 - val_acc: 0.8549\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 0.8217 - acc: 0.8942 - val_loss: 1.0319 - val_acc: 0.8553\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8207 - acc: 0.8943 - val_loss: 1.0343 - val_acc: 0.8539\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.8199 - acc: 0.8946 - val_loss: 1.0321 - val_acc: 0.8557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc05ff64940>"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwYf83ADnAh2"
   },
   "source": [
    "최종 에포크에서 훈련 데이터는 88%의 정확도를, 테스트 데이터에서는 85%의 정확도를 얻었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXSiXHWGnGIR"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3. seq2seq 기계 번역기 동작시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gogL_nfNnMZX"
   },
   "source": [
    "seq2seq는 훈련 과정과 테스트 과정에서의 동작 방식이 다릅니다. 그래서 테스트 과정을 위해 모델을 다시 설계해주어야 합니다. 특히 디코더를 많이 수정해야 합니다. 우선 테스트 과정에서의 인코더 모델을 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1596048280206,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "oQhg4BJcnCcl"
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ebeN8e5jnUkX"
   },
   "source": [
    "디코더를 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1596048282800,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "fS36ShX7nVXO"
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XKZkimanXVl"
   },
   "source": [
    "디코더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1596048285017,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "bmZx5RPznYZd"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CurgMZnRncEA"
   },
   "source": [
    "테스트 과정을 위한 모델 설계를 완료하였습니다. 이제 테스트 과정에서의 동작을 위한 decode_sequence 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1596048287066,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "W1DLQnbondiS"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxD4q8f5nf6K"
   },
   "source": [
    "결과 확인을 위한 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1596048290204,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "hASVoup2niGf"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubAORFqEnjy0"
   },
   "source": [
    "훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1742,
     "status": "ok",
     "timestamp": 1596048484113,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "---GDwxznlTQ",
    "outputId": "dac0d177-0e6b-434d-f10e-6cb73194e171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  we have a reservation . \n",
      "번역문 : nous avons une reservation . \n",
      "예측문 :  nous avons une voiture . \n",
      "\n",
      "\n",
      "원문 :  can i see you again ? \n",
      "번역문 : puis je te revoir ? \n",
      "예측문 :  puis je vous voir a l des il ont vous ? \n",
      "\n",
      "\n",
      "원문 :  what brings you here ? \n",
      "번역문 : qu est ce qui vous amene ici ? \n",
      "예측문 :  qu est ce qui vous a fait la faire ? \n",
      "\n",
      "\n",
      "원문 :  why did you buy it ? \n",
      "번역문 : pourquoi l avez vous achete ? \n",
      "예측문 :  pourquoi l as tu fait ? \n",
      "\n",
      "\n",
      "원문 :  tom will find you . \n",
      "번역문 : tom te trouvera . \n",
      "예측문 :  tom je pas ? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPLB2GPdnqFw"
   },
   "source": [
    "테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1725,
     "status": "ok",
     "timestamp": 1596048489451,
     "user": {
      "displayName": "고현웅",
      "photoUrl": "",
      "userId": "01574346278563741173"
     },
     "user_tz": -540
    },
    "id": "Fd9PCQgFnq53",
    "outputId": "ae48c67b-6ec5-4240-e0b7-943cf29310b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  he stopped drinking . \n",
      "번역문 : il a arrete de boire . \n",
      "예측문 :  il a se fait un pas de l air . \n",
      "\n",
      "\n",
      "원문 :  are you a wizard ? \n",
      "번역문 : es tu une sorciere ? \n",
      "예측문 :  es tu un d accord ? \n",
      "\n",
      "\n",
      "원문 :  who spoke ? \n",
      "번역문 : qui a parle ? \n",
      "예측문 :  qui a fait peux ? \n",
      "\n",
      "\n",
      "원문 :  what did you make ? \n",
      "번역문 : qu est ce que tu as fait ? \n",
      "예측문 :  qu as tu fait ? \n",
      "\n",
      "\n",
      "원문 :  whose phone is that ? \n",
      "번역문 : a qui est ce telephone ? \n",
      "예측문 :  a qui est ce livre ? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07_03_Seq2Seq_어텐션_메커니즘.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
