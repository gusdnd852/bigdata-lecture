{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 다양한 최적화 기법들\n",
    "> 다층 퍼셉트론을 최적화 하기 위한 다양한 기법들을 배워봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 6]\n",
    "- permalink: /mlp_optimization\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 옵티마이저 (Optimizer)\n",
    "\n",
    "딥러닝 모델을 학습하기 위해서 지금까지 Gradient Descent 알고리즘을 배웠습니다. 그러나 이러한 Gradient Descent 알고리즘은 기본적으로 많은 문제가 있습니다. 그에 대해 알아볼까요? <br><br>\n",
    "\n",
    "#### 1.1. 경사하강법(Gradient Descent) 복습\n",
    "\n",
    "뉴럴 네트워크의 loss function의 현 weight의 기울기(gradient)를 구하고 loss를 줄이는 방향으로 업데이트(조정)해 나가는 방법을 통해서 뉴럴 네트워크를 학습하였습니다. loss(cost) function이라는게 나왔군요. 뉴럴 네트워크에서 loss function은 무엇일까요? 간단히 설명하면 지금 현재의 가중치에서 \"틀린정도\"를 알려주는 함수이죠.\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/99E6363359D86A8805)\n",
    "\n",
    "즉, 현재 네트워크의 weight에서 내가 가진 데이터를 다 넣어주면 전체 에러가 계산 되겠죠? 거기서 미분을 하면 에러를 줄이는 방향을 알 수 있습니다. 바로 위의 그림과 같이 말이죠. 그 방향으로 정해진 스텝량(learning rate)을 곱해서 weight을 이동시킵니다. 이걸 계속 반복해서 학습을 하는 것이죠.\n",
    "<br><br>\n",
    "\n",
    "그러나 기존의 Gradient Descent 방식에는 크나큰 단점이 있었습니다. 위에서 적은 내용을 보시게 되면 한가지 큰 문제점을 발견할 수 있습니다. **최적값을 찾아 나가기 위해서 한칸 전진할 때마다 모든 데이터 셋을 넣어주어야 한다는 것**이죠. 그래서 학습이 굉장히 오래 걸리는 문제가 발생하게 되는 것이죠. 언제 다 학습시킬 것인가라는 문제가 발생한 것이죠. 그러면 Gradient Descent 말고 더 빠른 Optimizer는 없는지 연구자들이 고민을 하게 되죠 그래서 나온 것이 Stochastic Gradient Descent 입니다.\n",
    "<br><br>\n",
    "\n",
    "#### 1.2. 확률적 경사 하강법 (Stochastic Gradient Descent)\n",
    "\n",
    "Stochastic Gradient Descent(이하 SGD)의 아이디어는 간단합니다. 바로 \"조금만 훑어보고 빠르게 가봅시다\"라는 것이죠. GD와 SGD의 차이를 간단히 그림으로 비교해보면 아래의 그림과 같습니다.\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/999EA83359D86B6B0B)\n",
    "\n",
    "기본적으로 SGD는 데이터 1개만 보고 움직이는 것인데 그러면 학습이 너무 Noisy하게 되므로 조금 더 보완해서 **데이터 N개를 보고 움직이는 Mini Batch Traning 방식이 현재에도 많이 쓰이고 있습니다.** 이렇게 해야하는 가장 큰 이유는 사실 데이터셋이 너무 커서 메모리에 모두 올리지 못하기 때문이죠. 또한 일반 GD보다 SGD가 훨씬 나은 속도를 보여줍니다.\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/9961913359D86B9833)\n",
    "\n",
    "GD의 경우 항상 전체 데이터 셋을 가지고 한발자국 전진할 때마다(learning rate) 최적의 값을 찾아 나아가고 있는 모습을 볼수 있습니다. 그러나 SGD는 Mini-batch 사이즈 만큼 조금씩 돌려서 최적의 값으로 가고 있습니다. 흠... 꽤 괜찮아 보입니다. 그러나 SGD에도 문제점이 존재합니다. 미니 배치를 통해 학습을 시키는 경우 최적의 값을 찾아 가기 위한 방향 설정이 뒤죽 박죽입니다.\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/9969013359D86BD731)\n",
    "\n",
    "또 다른 문제점은 스텝의 사이즈입니다. 이것을 다른 말로 정의하면 learning rate입니다. 한걸음 나아가기 위한 보폭이 낮으면 학습하는데 오래 걸리고, 너무 크면 최적의 값을 찾지 못하는 문제가 있겠습니다. 도대체 어떤 learning rate를 적용해야하는가에 대한 문제도 존재하죠.\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/999A143359D86C022F)\n",
    "\n",
    "\n",
    "그래서 최근의 연구에서는 이러한 SGD의 문제점을 인지하고 각각의 문제점들을 개선하는 더 좋은 Optimizer들이 많이 있습니다. 새로운 Optimizer 들에 대해 알아보도록 하겠습니다.\n",
    "<br><br>\n",
    "\n",
    "#### 1.3. SGD의 문제 점\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/60.png?raw=true)\n",
    " \n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/61.png?raw=true)\n",
    "\n",
    "만약 오차함수가 위처럼 만들어졌다고 생각해봅시다. 딥러닝에서 오차함수는 어떤 모양이든 가능하기 때문에 이러한 가정이 문제될 것은 없습니다. <br><br> 위 함수의 경우 위 그림의 왼쪽과 같이 '밥그릇'을 x축 방향으로 늘인 듯한 모습이고, 실제로 이 등고선은 오른쪽과 같이 x축 방향으로 늘인 타원으로 되어 있습니다.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/62.png?raw=true)\n",
    "\n",
    "이 기울기의 y축 방향은 크고 x축 방향은 작다는 것이 특징입니다. 말하자면 y축 방향은 가파른데 x축 방향은 완만한 것입니다. 또, 여기에서 주의할 점으로는 위 식이 최솟값이 되는 장소는 (x, y) = (0, 0)이지만, 위의 그림이 보여주는 기울기 대부분은 (0, 0) 방향을 가리키지 않는다는 것입니다. 그러니까, 만약 x가 -5나 +5와 같은 곳으로 잡히면 (0, 0)으로 갈 수가 없습니다. <br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/63.png?raw=true)\n",
    "\n",
    "이제 위 함수에 SGD를 적용해볼까요? 탐색을 시작하는 장소(초깃값)는 (x, y) = (-7.0, 2.0)으로 하자. 결과는 위와 같습니다. SGD는 위 그림과 같이 심하게 굽이진 움직임을 보여줍니다. 상당히 비효율적입니다. 즉, SGD의 단점은 비등방성(anisotropy) 함수(이렇게 축마다 기울기가 크게 상이한 함수)에서는 탐색 경로가 비효율적이라는 것입니다. <br><br>\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/993D383359D86C280D)\n",
    "\n",
    "때문에 위 그림과 같이 SGD의 스텝방향(파란색)의 문제점을 집중적으로 개선한 알고리즘들과 스텝 사이즈(빨간색)를 얼마나 하는게 좋을 것인가에 대한 알고리즘들이 집중적으로 연구되어왔으며 마지막엔 이러한 2가지 방법을 같이 사용한 알고리즘들이 나왔습니다. 그럼 한번 각 알고리즘의 성능에 관하여 그림으로 살펴보면 아래와 같습니다.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/57.gif?raw=true)\n",
    " \n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/58.gif?raw=true)\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/59.gif?raw=true)\n",
    " \n",
    "위 그림들을 보시면 매우 다양한 학습 알고리즘이 존재하고, 우리가 지금까지 썼던 SGD가 제일 안좋은것처럼 보입니다. SGD는 단순하고 구현도 쉽지만, 문제에 따라서는 비효율적일 때가 있습니다. \n",
    "<br><br>\n",
    "\n",
    "그럼 이제부터 SGD의 이러한 단점을 개선해주는 몇가지 알고리즘을 간단하게 소개해드리도록 하겠습니다. <br><br>\n",
    "\n",
    "#### 1.4. 모멘텀\n",
    "\n",
    "모멘텀(Momentum)은 '운동량'을 뜻하는 단어로, 물리와 관계가 있습니다. 모멘텀 기법은 수식으로는 다음과 같습니다.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/64.png?raw=true)\n",
    "\n",
    "기존의 Gradient Descent 알고리즘에 $\\alpha \\triangle w$가 더해져있습니다. 이 때, $ \\triangle w$는 이전 스텝의 이동량으로 이해하시면 됩니다. 이 것은 움직임에 있어서 '관성'의 의미와 매우 흡사합니다. 관성을 추가함으로서 새로운 이동량은 이전의 이동량에 영향을 받게 됩니다. 그래서 이동량이 급격하게 변화하는 것을 막습니다. 또한 Local Minimum에 빠지는 문제가 어느정도는 보완됩니다. <br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/67.png?raw=true)\n",
    "\n",
    "딥러닝의 경우 찾고자 하는 함수 자체가 비선형함수이기 때문에 Loss 함수가 밥그릇 모양(전문용어로는 Convex하다고 합니다)이라는 보장이 없습니다. 즉, $(y - \\hat{y})^2$이 2차식일거라는 보장이 없습니다. $\\hat{y}$이 어떻게 생긴지 모르니까요. 때문에 아래와 같은 모습의 Loss함수도 가능한데, 기존 SGD의 경우 Local Minimum 지점에서 기울기가 0이 되기 때문에 움직일가 없습니다. 그래서 더 낮은 위치인 Global Minimum에 도달할 수 없습니다. \n",
    "\n",
    "![](https://lh3.googleusercontent.com/proxy/qfD-puc3c0jf9TrQTeYuKp1t0eAgLYZrLVsoq-kbVbaBnW18BLT4-0NpZcUnMWhvPdmfQJRpyvY7eqK9oK7urSR95luj97JCXs3hfEg)\n",
    "\n",
    "그러나 관성이 추가되면 이전에 급한 기울기로 이동해왔다면 저러한  Local Minimum을 뛰어넘고 Global Minimum까지 도달할 수도 있게 됩니다. <br><br>\n",
    "\n",
    "그러나 사실 딥러닝 모델이 왜 Local Minimum에 잘 빠지지 않고 거의 대부분의 경우 Global Minimum으로 이동하는지에 대한 이유는 아직도 밝혀지지가 않았습니다. 모멘텀이 Local Minimum 탈출에 도움을 줄 수 있긴 하지만 항상 모멘텀만으로 Local Minimum을 탈출한다고 말하기는 어려울 것입니다. <br><br>\n",
    "\n",
    "흔히 인터넷에서 딥러닝이 왜 잘되는지 모른다는 이유가 여기에 있습니다. 딥러닝 모델은 너무 쉽게 Loss함수에서 Global Minimum을 찾아 움직입니다. 그런데 왜 그런지는 아직도 밝혀진바가 없습니다. 무튼, 이러한 기법이 바로 모멘텀(관성)기법입니다.\n",
    "\n",
    "- SGD : 매번 왔다갔다 하면서 이동하게 됨.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/63.png?raw=true)\n",
    "\n",
    "- Momentum : 이전에 움직였던 방향이 더해져서 꺾일 때, 과하게 꺾이지 않음\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/66.png?raw=true)\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.compile(optimizer=optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# 보통 momentum은 0.9를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. AdaGrad\n",
    "\n",
    "신경망 학습에서는 학습률(수식에서는 η) 값이 중요하다. 이 값이 너무 작으면 학습 시간이 너무 길어지고, 반대로 너무 크면 발산하여 학습이 제대로 이뤄지지 않습니다.\n",
    "\n",
    "이 학습률을 정하는 효과적 기술로 **학습률 감소(learning rate decay)가 있습니다.** 이는 학습을 진행하면서 학습률을 점차 줄여가는 방식인데요. 초반에는 빠르게 성큼성큼 움직이다가 후반에는 조금씩 가서 미세조정에 도움을 줍니다. 학습률을 서서히 낮추는 가장 간단한 방법은 매개변수 '전체'의 학습률 값을 일괄적으로 낮추는 것입니다. 이를 더욱 발전시킨 것이 AdaGrad입니다. AdaGrad는 '각각의' 매개변수에 '맞춤형' 값을 만들어 줍니다.\n",
    "\n",
    "- SGD : 매번 크게 움직임\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/63.png?raw=true)\n",
    "\n",
    "- AdaGrad : 초반에만 크게 움직이고 학습이 진행될수록 움직임이 크게 작아져서 미세조정에 도움이 됨.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/68.png?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.compile(optimizer=optimizers.Adagrad(lr=0.005),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.6. Adam (AdaGrad + Momentum)\n",
    "\n",
    "모멘텀은 공이 그릇 바닥을 구르는 듯한 움직임을 보였습니다. AdaGrad는 매개변수의 원소마다 적응적으로 갱신 정도를 조정했었죠. 그 두기법을 융합한 아이디어에서 출발한 기법이 바로 Adam입니다. <br><br>\n",
    "\n",
    "잘 모르겠으면 일단 Adam을 사용하라는 말이 있을 정도로 성능이 우수합니다. Adam은 학습률을 줄여나가고 속도를 계산하여 학습의 갱신강도를 적응적으로 조정해나가는 방법입니다.  <br><br>\n",
    "\n",
    "- SGD : 매번 크게 왔다갔다 움직임.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/63.png?raw=true)\n",
    "\n",
    "- Adam : 이전에 움직였던 방향이 더해져서 꺾일 때, 과하게 꺾이지 않으면서 시간이 지날수록 learning rate가 감소해서 미세조정에 도움이 됨.\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/69.png?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일 및 학습 진행\n",
    "\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# 그냥 웬만하면 Adam 쓰면 성능 제일 잘 나옵니다.\n",
    "net.compile(optimizer=optimizers.Adam(lr=0.005),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. Regularization (정규화 = Weight Decay, 가중치 감쇠)\n",
    "\n",
    "Overfitting의 문제를 피하기 위한, 가장 확실한 대책 중 하나는 훈련 데이터(Training data)의 양을 늘리는 것입니다. 하지만, 훈련 데이터는 아무런 대가 없이 그냥 얻어지는 것이 아닙니다. 양질의 훈련 데이터를 얻으려면 많은 시간과 비용을 필요로 하며, 어떤 경우는 추가 데이터의 확보가 어렵거나 불가능한 경우도 있죠. 또한, 학습 데이터의 양이 많아지면 결과적으로 학습에 걸리는 시간이 늘어나는 문제도 있습니다.\n",
    "<br><br>\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/70.png?raw=true)\n",
    "\n",
    "이 때 사용하는 방식이 regularization입니다. Regularization은 ‘정규화’라는 말로 번역이 되기도 하지만, ‘일반화’ 라고 번역을 하는 것이 더 적합한 것 같습니다. 이 용어는 기계 학습뿐만 아니라 통계에서도 흔히 사용이 되는 용어입니다. Regularization은 일종의 penalty 조건에 해당이 됩니다. <br><br>\n",
    "\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day5/reg07.png?raw=true)\n",
    "\n",
    "사실 우리는 다양한 회귀모델 시간에 이미 Regularization에 대해서 배웠습니다. 바로 Ridge(L1), Lasso(L2), Elastic Net(혼합)이 Regularization에 해당하는데요. 다중공선성이 있는 데이터에 대해서 그냥 고전적인 선형 회귀 모델을 만들게 되면 **특정 회귀 계수의 영향력이 과다 추정**될 수 있습니다고 했습니다. 이 때, Weight값을 Loss함수에 더하면, Loss함수가 최소화되면서 Weight의 norm도 같이 크기가 작아져서, 어느 한가지 Weight가 급격하게 높은 영향력을 행사하는 것을 방지했었죠. <br><br>\n",
    "\n",
    "딥러닝에서도 마찬가지로 이 Regularization이 동일하게 동작합니다. **Regularization은 Weight들의 크기를 줄인다고 해서 다른 이름으로 Weight Decay라고도 불립니다.** Tensorflow에서는 Weight 블록(Dense)에 kernel_regularizer를 설정하여 적용할 수 있습니다. 이때 파라미터로 넣는 숫자는 regularization을 얼마나 강하게 적용할지에 대한 파라미터인 $\\lambda$에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 regularization : Ridge Regression\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l1(0.01))\n",
    "        \n",
    "        self.output_layer = Dense(3, \n",
    "                                  activation='softmax',\n",
    "                                  kernel_regularizer=l1(0.01))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2 regularization : Lasso Regression\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l2(0.01))\n",
    "        \n",
    "        self.output_layer = Dense(3, \n",
    "                                  activation='softmax',\n",
    "                                  kernel_regularizer=l2(0.01))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 l2 regularization : Elastic Net Regression\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l1_l2(0.01))\n",
    "        \n",
    "        self.output_layer = Dense(3, \n",
    "                                  activation='softmax',\n",
    "                                  kernel_regularizer=l1_l2(0.01))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. Weight Initialization (가중치 초기화)\n",
    "\n",
    "![](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day6/71.png?raw=true)\n",
    "\n",
    "딥러닝 학습에 있어 초기 가중치(w) 설정은 매우 중요한 역활을 합니다. 우리는 지금까지 weight를 그냥 랜덤한 값으로 만들었습니다. 그러나 이게 과연 잘 초기화 한 것일까요? <br><br>\n",
    "\n",
    "가중치를 잘못 설정할 경우 기울기 소실 문제나 표현력의 한계를 갖는 등 여러 문제를 야기하게 됩니다. 또한 딥러닝의 학습의 문제가 non-convex 이기 때문에 초기값을 잘못 설정할 경우 local minimum에 수렴할 가능성이 커지게 됩니다. 따라서 여기에서는 두가지 초기화 방법을 소개드립니다. <br><br>\n",
    "\n",
    "- 1. xavier(glorot) initialization\n",
    "\n",
    "sigmoid와 같이 비선형 activiation을 쓰는 경우에 사용하면 좋습니다. xavier initialization은 매우 간단한데 그냥 랜덤값으로 초기화된 가중치에 $\\sqrt{\\frac{2}{size_{in} + size_{out}}}$을 곱해주면 됩니다. 이렇게 값을 줄이면 평균 0으로부터의 분산의 크기가 작아지기 때문에 특이하게 튀는 값들이 적고 더욱 평탄한 분포를 갖게되기 때문에 학습과정이 더욱 수월해집니다.\n",
    "<br><br>\n",
    "\n",
    "- 2. he initialization \n",
    "\n",
    "relu와 같은 activiation을 쓰는 경우에 사용하면 좋습니다. he initialization은 매우 간단한데 xavier initialization에서 input size의 영향을 제거한 것입니다. 따라서 랜덤값으로 초기화된 가중치에 $\\sqrt{\\frac{2}{size_{in}}}$을 곱해주면 됩니다.\n",
    "<br><br>\n",
    "\n",
    "Tensorflow에서 이러한 가중치 초기화 기법들을 사용해볼까요? 우리가 이전시간에 사용했던 Dense 블록과 같은 Layer에 `kernel_initializer`를 변경함으로서 초기화방법을 지정해줄 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier Glorot Initialization\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='glorot_normal')\n",
    "        \n",
    "        self.output_layer = Dense(3, \n",
    "                                 activation='softmax',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='glorot_normal')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaming He Initialization\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='he_normal')\n",
    "        \n",
    "        self.output_layer = Dense(3, \n",
    "                                 activation='softmax',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='he_normal')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. Dropout (드롭아웃) : 신경망 앙상블 기법\n",
    "\n",
    "![](https://user-images.githubusercontent.com/26705935/59435006-a5521700-8e27-11e9-881e-5b8c0e8049b7.png)\n",
    "\n",
    "Dropout은 간단하지만 아주 강력한 정규화(regularization)기법입니다. 최근 나온 기법들에 밀리지 않고 여전히 유용하고 좋은 성능을 보여줍니다. <br><br>\n",
    "\n",
    "훈련을 통해 학습되는 머신러닝 및 딥러닝의 특성상, 무작위로 초기화되고 무작위로 데이터에 접근한다는 방식 때문에 같은 데이터로 훈련한 모델이더라도 다른 결과를 낼 수 있습니다. 하지만, **같은 데이터로 여러 개의 서로 다른 모델을 훈련한 뒤 그 결과를 다수결 등으로 종합해 보면 통계적으로 덜 '튀는' 결과가 나와 더 높은 정답률을 얻게 됩니다.**<br><br>\n",
    "\n",
    "이 방식을 앙상블(ensemble) 모델이라고 합니다. 우리는 이미 랜덤포레스트, 부스팅 등의 앙상블 모델에 대해서 배웠습니다. 그러면 신경망은 어떻게 앙상블 할 수 있을까요? 신경망은 그 크기가 무겁고 느리기 때문에 앙상블하기 어렵습니다(정확히 말하면 가능하긴 한데 느립니다), 그러나 Dropout과 같은 기법을 사용하면 단 하나의 신경망으로 앙상블을 흉내낼 수 있습니다. <br><br>\n",
    "\n",
    "Dropout은 비록 모델은 여러 개를 만들지 못하지만 훈련 과정에서 앙상블의 효과를 내게 됩니다. 같은 변수들을 공유하는 하나의 모델만을 사용한다는 점이 일반적인 앙상블 모델과 다른 점입니다. 하나의 인공신경망에서 **앙상블을 실현시키기 위해서, 훈련 단계에서 dropout 은 강제로 특정 퍼셉트론을 없애버립니다.** 그 과정에서 그 퍼셉트론에 연결된 가중치들도 의미없는 값이 됩니다.  매번 입력이 들어올 때마다 무작위로 다른 퍼셉트론들을 끊어냅니다. \n",
    "<br><br>\n",
    "\n",
    "![](https://deepestdocs.readthedocs.io/en/latest/004_deep_learning_part_2/image/0042_fig0.jpg)\n",
    "\n",
    "이 과정에서 **약간씩 다른, 엄청 다양한 구조가 학습된다고 생각할 수 있습니다.** 위 처럼 하나의 네트워크지만 연결 형태를 매우 다양하게 해봄으로서 다양한 경우에 대한 학습이 가능합니다. 즉, 하나의 네트워크를 매우 여러개로 만들어보면서 학습함으로서 앙상블의 효과를 간접적으로 체험할 수 있게 됩니다. <br><br>\n",
    "\n",
    "\n",
    "Tensorflow에서는 Dense 블록 이외에 Dropout 블록을 사용할 수 있습니다. 원하는 시점에서 뉴런들의 연결을 끊어낼 수 있습니다. 이때 파라미터로 들어가는 rate는 몇 %의 퍼셉트론을 끊어낼 것인가를 나타냅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaming He Initialization\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = Dense(512, \n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='he_normal')\n",
    "\n",
    "        self.drop_out = Dropout(0.5)\n",
    "        self.output_layer = Dense(3, \n",
    "                                 activation='softmax',\n",
    "                                 kernel_regularizer=l2(0.01),\n",
    "                                 kernel_initializer='he_normal')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.drop_out(x) # 연결을 끊어냅니다.\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
