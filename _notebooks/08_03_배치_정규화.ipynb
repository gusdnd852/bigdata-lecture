{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_03_배치_정규화.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNROEi+CifWgrEFpwboDEEk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UEsuFIM4_cWo","colab_type":"text"},"source":["# 03. 배치 정규화 (Batch Normalization)\n","> 딥러닝 내부의 입력을 표준화 시켜주는 배치 정규화에 대해 알아봅시다.\n","\n","- toc: true \n","- badges: true\n","- comments: true\n","- categories: [Day 8]\n","- permalink: /batch_normalization\n","- exec: colab"]},{"cell_type":"markdown","metadata":{"id":"nvuPpT0qCohB","colab_type":"text"},"source":["이전 시간에 심층 신경망 학습에서는 DNN 학습에 있어서 적절한 활성화 함수 및 가중치 초기화 방법에 대해 알아보았습니다. 이번 포스팅에서는 그래디언트 소실(vanishing gradient)과 폭주(exploding) 문제를 해결하는 방법인 배치 정규화(BN, Batch Normalization)와 그래디언트 클리핑(Gradient Clipping), 그리고 학습 속도를 높일 수 있는 최적화(Optimization) 방법에 대해 알아봅시다.\n"]},{"cell_type":"markdown","metadata":{"id":"9RcwA0ODCv-e","colab_type":"text"},"source":["<br> \n","\n","### 1. 배치 정규화 (BN, Batch Normalization)\n","\n","#### 1.1. 배치정규화란?\n","다층 신경망 학습에서는 활성화 함수로는 ReLU를 사용하고 He 초기화를 통해 학습 초기 단계에서의 그래디언트 소실/폭주 문제를 줄일 수 있었지만, 이러한 문제가 학습하는 동안에 또 다시 발생할 가능성이 있습니다. <br><br>\n","\n","2015년 Sergety Ioffe와 Christian Szegedy는 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift'라는 논문에서 배치 정규화(BN, Batch Normalization)를 제안했습니다.  배치 정규화는 각 층의 활성화 함수의 출력값 분포가 골고루 분포되도록 '강제'하는 방법으로, 각 층에서의 활성화 함수 출력값이 정규분포(normal distribution)를 이루도록 하는 방법입니다. \n","<br><br>\n","\n","즉, 학습하는 동안 이전 레이어에서의 가중치 매개변수가 변함에 따라 활성화 함수 출력값의 분포가 변화하는 내부 공변량 변화(Internal Covariate Shift) 문제를 줄이는 방법이 바로 배치 정규화 기법입니다. 배치 정규화는 아래의 그림과 같이 미니배치(mini-batch)의 데이터에서 각 feature(특성)별 평균(​mean)과 분산(​variance)을 구한 뒤 정규화(normalize) 해줍니다.\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F99166C4B5BBDFFFA279D59)\n","\n","일반적으로 배치 정규화는 아래의 그림과 같이 Dense Block이나 Convolutional Block 바로 다음, 그리고 활성화 함수를 통과하기 전에 배치 정규화(BN)레이어를 삽입하여 사용합니다.\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile29.uf.tistory.com%2Fimage%2F994586445BBE000E15CC3D)\n","\n","배치 정규화는 미니배치(mini-batch)를 단위로 데이터의 분포가 평균(​mean)이 0, 분산(variance)이 1이 되도록 정규화(normalization)합니다. 수식은 다음과 같습니다.\n","\n","![](https://shuuki4.files.wordpress.com/2016/01/bn1.png)\n","<br><br>\n","\n","\n","#### 1.2. 배치정규화의 장점\n","\n","Batch Normalization(BN)은 논문에서 실험했던 모든 딥 뉴럴넷의 성능이 크게 향상 시켰습니다. BN은 다음과 같은 장점들이 있습니다. \n","\n","- tanh나 sigmoid 같은 활성화 함수에 대해 그래디언트 소실(vanishing gradient)문제가 감소합니다.\n","\n","- 가중치 초기화에 덜 민감합니다. 가중치 초기값에 크게 의존하지 않기 때문에 이전에 알아본 가중치 초기화 기법에 대해 크게 신경 쓰지 않아도 됩니다.\n","\n","- 학습률(learning rate)를 크게 잡아도 gradient descent가 잘 수렴합니다.\n","\n","- 오버피팅을 억제합니다. BN이 마치 Regularization 역할을 하기 때문에 드롭아웃(Dropout)과 같은 규제기법에 대한 필요성이 감소합니다.  하지만, BN로 인한 규제는 효과가 크지느ㄴ 않기 때문에 드롭아웃을 함께 사용하는 것이 좋습니다.\n","<br><br>\n","\n","#### 1.3. Tensorflow에서 배치 정규화 사용하기\n","\n","- MLP(다층퍼셉트론)에서 사용하기\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8nKSdEW0GiNY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068941594,"user_tz":-540,"elapsed":1290,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["# 데이터셋 로드\n","\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.datasets import load_iris\n","\n","\n","iris = load_iris()\n","feature = iris.data\n","label = iris.target\n","label = np.expand_dims(label, axis=1)\n","\n","iris = np.concatenate([feature, label], axis=1)\n","np.random.shuffle(iris)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2LZOV6KHAIo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596068945850,"user_tz":-540,"elapsed":916,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"7fa61da6-0ab1-4631-8b46-c01f2d721c8e"},"source":["# 학습, 테스트 데이터셋 분할\n","\n","feature = iris[:, :4]\n","label = iris[:, 4:]\n","\n","split_point = int(0.8 * len(feature))\n","train_feature, train_label = feature[:split_point], label[:split_point]\n","test_feature, test_label = feature[split_point:], label[split_point:]\n","\n","print(train_feature.shape, train_label.shape)\n","print(test_feature.shape, test_label.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(120, 4) (120, 1)\n","(30, 4) (30, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gzsBVf1THBXi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068949273,"user_tz":-540,"elapsed":1073,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["# 신경망 구현 (Class)\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, ReLU, BatchNormalization\n","\n","class NeuralNetwork(Model):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.relu = ReLU() # 액티베이션 함수 밖으로 빼기\n","\n","        self.dense1 = Dense(512)\n","        self.bn1 = BatchNormalization()\n","        self.dense2 = Dense(512)\n","        self.bn2 = BatchNormalization()\n","        self.out = Dense(3, activation='softmax')\n","\n","    def call(self, x):\n","      # 순서 : dense - bn - relu\n","\n","        x = self.dense1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.dense2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","\n","        x = self.out(x)\n","        return x"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KST9L7xHtw-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596068989716,"user_tz":-540,"elapsed":6108,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"549db997-f21c-4518-a8d0-f3121e1d8911"},"source":["# 컴파일 및 학습 진행\n","\n","from tensorflow.keras import losses\n","from tensorflow.keras import metrics\n","from tensorflow.keras import optimizers\n","\n","\n","net = NeuralNetwork()\n","net.compile('adam',\n","            loss='sparse_categorical_crossentropy',\n","            metrics=['accuracy'])\n","\n","net.fit(train_feature, train_label, epochs=150)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7500\n","Epoch 2/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9500\n","Epoch 3/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9750\n","Epoch 4/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9667\n","Epoch 5/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9917\n","Epoch 6/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9833\n","Epoch 7/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9917\n","Epoch 8/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9667\n","Epoch 9/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9667\n","Epoch 10/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9750\n","Epoch 11/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9583\n","Epoch 12/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9750\n","Epoch 13/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9750\n","Epoch 14/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9750\n","Epoch 15/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9833\n","Epoch 16/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9750\n","Epoch 17/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9667\n","Epoch 18/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9583\n","Epoch 19/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9833\n","Epoch 20/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9667\n","Epoch 21/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9750\n","Epoch 22/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9833\n","Epoch 23/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9917\n","Epoch 24/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9833\n","Epoch 25/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9667\n","Epoch 26/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9833\n","Epoch 27/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9750\n","Epoch 28/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9667\n","Epoch 29/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9750\n","Epoch 30/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9833\n","Epoch 31/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9667\n","Epoch 32/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9833\n","Epoch 33/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9500\n","Epoch 34/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9583\n","Epoch 35/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9750\n","Epoch 36/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9667\n","Epoch 37/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9667\n","Epoch 38/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9500\n","Epoch 39/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9917\n","Epoch 40/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9917\n","Epoch 41/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9833\n","Epoch 42/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9750\n","Epoch 43/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9833\n","Epoch 44/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000\n","Epoch 45/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9917\n","Epoch 46/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1522 - accuracy: 0.9500\n","Epoch 47/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9750\n","Epoch 48/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9667\n","Epoch 49/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9417\n","Epoch 50/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9500\n","Epoch 51/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9917\n","Epoch 52/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9833\n","Epoch 53/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 1.0000\n","Epoch 54/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9667\n","Epoch 55/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9750\n","Epoch 56/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9833\n","Epoch 57/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9917\n","Epoch 58/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9750\n","Epoch 59/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9917\n","Epoch 60/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9667\n","Epoch 61/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9917\n","Epoch 62/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9583\n","Epoch 63/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000\n","Epoch 64/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9917\n","Epoch 65/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9583\n","Epoch 66/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9917\n","Epoch 67/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9917\n","Epoch 68/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9917\n","Epoch 69/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9917\n","Epoch 70/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000\n","Epoch 71/150\n","4/4 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9833\n","Epoch 72/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9750\n","Epoch 73/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9917\n","Epoch 74/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9750\n","Epoch 75/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9583\n","Epoch 76/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9750\n","Epoch 77/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9667\n","Epoch 78/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9667\n","Epoch 79/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9833\n","Epoch 80/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.9750\n","Epoch 81/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9667\n","Epoch 82/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 1.0000\n","Epoch 83/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9917\n","Epoch 84/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9833\n","Epoch 85/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9833\n","Epoch 86/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9833\n","Epoch 87/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9917\n","Epoch 88/150\n","4/4 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9833\n","Epoch 89/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9917\n","Epoch 90/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9917\n","Epoch 91/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9750\n","Epoch 92/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9833\n","Epoch 93/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9917\n","Epoch 94/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000\n","Epoch 95/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9833\n","Epoch 96/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9917\n","Epoch 97/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9917\n","Epoch 98/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9500\n","Epoch 99/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 1.0000\n","Epoch 100/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9750\n","Epoch 101/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 1.0000\n","Epoch 102/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000\n","Epoch 103/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 1.0000\n","Epoch 104/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000\n","Epoch 105/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 106/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000\n","Epoch 107/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9917\n","Epoch 108/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9917\n","Epoch 109/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9917\n","Epoch 110/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9750\n","Epoch 111/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9833\n","Epoch 112/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9833\n","Epoch 113/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9667\n","Epoch 114/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9583\n","Epoch 115/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9833\n","Epoch 116/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1270 - accuracy: 0.9333\n","Epoch 117/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9833\n","Epoch 118/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9667\n","Epoch 119/150\n","4/4 [==============================] - 0s 7ms/step - loss: 0.0983 - accuracy: 0.9583\n","Epoch 120/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9667\n","Epoch 121/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1086 - accuracy: 0.9417\n","Epoch 122/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9917\n","Epoch 123/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9500\n","Epoch 124/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9667\n","Epoch 125/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9917\n","Epoch 126/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9833\n","Epoch 127/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9917\n","Epoch 128/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1530 - accuracy: 0.9667\n","Epoch 129/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9833\n","Epoch 130/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9833\n","Epoch 131/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9917\n","Epoch 132/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9833\n","Epoch 133/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9917\n","Epoch 134/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9917\n","Epoch 135/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9750\n","Epoch 136/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 1.0000\n","Epoch 137/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9917\n","Epoch 138/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9917\n","Epoch 139/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9750\n","Epoch 140/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 1.0000\n","Epoch 141/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9917\n","Epoch 142/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9667\n","Epoch 143/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9917\n","Epoch 144/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9917\n","Epoch 145/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9833\n","Epoch 146/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9917\n","Epoch 147/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9833\n","Epoch 148/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9917\n","Epoch 149/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9750\n","Epoch 150/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f012abf50f0>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"BJLj7UQNIF00","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596069018233,"user_tz":-540,"elapsed":1362,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"9a9f6dec-4793-4161-8b2a-a2df1667ca2a"},"source":["# 검증 과정\n","\n","net.evaluate(test_feature, test_label)[1]"],"execution_count":16,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9333\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9333333373069763"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"ryw9w3AjIIHZ","colab_type":"text"},"source":["<br>\n","\n","- CNN에서 사용하기"]},{"cell_type":"code","metadata":{"id":"PWnNI9sqFUlk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068382350,"user_tz":-540,"elapsed":936,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, ReLU, BatchNormalization\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.datasets import mnist\n","\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVO2Q7QQFhDS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068525462,"user_tz":-540,"elapsed":905,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["class BatchNormCNN(Model):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        self.relu = ReLU() # 액티베이션 함수 밖으로 빼기\n","\n","        self.conv1 = Conv2D(32, kernel_size=(3, 3))\n","        self.bn1 = BatchNormalization()\n","        self.pool1 = MaxPooling2D(pool_size=2)\n","\n","        self.conv2 = Conv2D(64, kernel_size=(3, 3))\n","        self.bn2 = BatchNormalization()\n","        self.pool2 = MaxPooling2D(pool_size=2)\n","        \n","        self.flatten = Flatten()\n","        self.hidden = Dense(256)\n","        self.out = Dense(10, activation='softmax')\n","        \n","        \n","    def call(self, x):\n","        # 순서 : conv- bn - relu\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.pool1(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.pool2(x)\n","\n","        x = self.flatten(x)\n","        x = self.hidden(x)\n","        x = self.out(x)\n","        return x"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"muqlX83IGEmT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1596068485725,"user_tz":-540,"elapsed":1499,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"d22c8503-43b1-4830-e4d9-18ba3a016028"},"source":["(train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n","train_feature = train_feature.astype(np.float32)\n","test_feature = test_feature.astype(np.float32)\n","\n","print(train_feature.shape, train_label.shape)\n","print(test_feature.shape, test_label.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","(60000, 28, 28) (60000,)\n","(10000, 28, 28) (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DlYRTXHqGF6N","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068495556,"user_tz":-540,"elapsed":924,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["train_feature = np.expand_dims(train_feature, axis=3)\n","test_feature = np.expand_dims(test_feature, axis=3)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5fU4cEaGIQg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596068510010,"user_tz":-540,"elapsed":1060,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"6f0d0188-e01f-4c81-a3ee-ec6d71a2316d"},"source":["print(train_feature.shape, train_label.shape)\n","print(test_feature.shape, test_label.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1) (60000,)\n","(10000, 28, 28, 1) (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3GsdMMDBGMAP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596068515537,"user_tz":-540,"elapsed":944,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}}},"source":["train_feature /= 255.0\n","test_feature /= 255.0"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCeX7XZHGQCh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":526},"executionInfo":{"status":"ok","timestamp":1596068541872,"user_tz":-540,"elapsed":1085,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"5fa476dd-8994-4223-9849-af0850231e8a"},"source":["cnn = BatchNormCNN()\n","cnn.build((None, *train_feature.shape[1:]))\n","cnn.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"batch_norm_cnn\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","re_lu (ReLU)                 multiple                  0         \n","_________________________________________________________________\n","conv2d (Conv2D)              multiple                  320       \n","_________________________________________________________________\n","batch_normalization (BatchNo multiple                  128       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) multiple                  0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            multiple                  18496     \n","_________________________________________________________________\n","batch_normalization_1 (Batch multiple                  256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 multiple                  0         \n","_________________________________________________________________\n","flatten (Flatten)            multiple                  0         \n","_________________________________________________________________\n","dense (Dense)                multiple                  409856    \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  2570      \n","=================================================================\n","Total params: 431,626\n","Trainable params: 431,434\n","Non-trainable params: 192\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rd3bRhP9GUYm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"ok","timestamp":1596068922977,"user_tz":-540,"elapsed":372423,"user":{"displayName":"고현웅","photoUrl":"","userId":"01574346278563741173"}},"outputId":"cbf9ac06-a9c7-42bd-b2b0-997d2a19de54"},"source":["cnn.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","cnn.fit(train_feature, train_label, epochs=5, batch_size=32)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.1997 - accuracy: 0.9532\n","Epoch 2/5\n","1875/1875 [==============================] - 74s 39ms/step - loss: 0.0637 - accuracy: 0.9809\n","Epoch 3/5\n","1875/1875 [==============================] - 74s 39ms/step - loss: 0.0507 - accuracy: 0.9845\n","Epoch 4/5\n","1875/1875 [==============================] - 74s 39ms/step - loss: 0.0376 - accuracy: 0.9880\n","Epoch 5/5\n","1875/1875 [==============================] - 74s 40ms/step - loss: 0.0323 - accuracy: 0.9900\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f013bdd6f28>"]},"metadata":{"tags":[]},"execution_count":9}]}]}